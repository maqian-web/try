{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# COMP 7310 Personal Project","metadata":{}},{"cell_type":"markdown","source":"### 1. Config Setup","metadata":{}},{"cell_type":"code","source":"# Make Dirs for Model Storage and Test Results\nimport os\n\ntry:\n    # Model Storage Path\n    model_prediction_path = '/kaggle/working/prediction_model'\n    os.mkdir(model_prediction_path)\nexcept:\n    pass\ntry:\n    # Test Results Path\n    test_result_path = '/kaggle/working/test_results'\n    os.mkdir(test_result_path)\nexcept:\n    pass\ntry:\n    # Test Seen & Unseen Path\n    os.mkdir(test_result_path + '/test_seen')\n    os.mkdir(test_result_path + '/test_unseen')\nexcept:\n    pass","metadata":{"execution":{"iopub.status.busy":"2023-10-27T12:39:25.575465Z","iopub.execute_input":"2023-10-27T12:39:25.576290Z","iopub.status.idle":"2023-10-27T12:39:25.582323Z","shell.execute_reply.started":"2023-10-27T12:39:25.576254Z","shell.execute_reply":"2023-10-27T12:39:25.581387Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nconfig settings:\n\"\"\"\n### TFNET parameters\nBATCH_SIZE = 72 # Training batch size\nTEST_BATCH_SIZE = 1 # Test batch size\nEPOCHS = 150 # Traning epoch\nSAVE_INTERVAL = 20 # Save model every 20 epochs\nSTEP_SIZE = 200 # Step size for moving forward the window (For training)\nTEST_STEP_SIZE = 400 # Step size for moving forward the window (For testing)\nWINDOW_SIZE = 400 # Window size for training and testing\nINPUT_CHANNEL = 6 # Input feature dimension (Gryo + Acce)\nOUTPUT_CHANNEL = 2 # Output dimension (2D velocity vector)\nSAMPLING_RATE = 200 # Sampling rate\nLAYER_SIZE = 100 # The size of LSTM\nLAYERS = 3 # The layer size of LSTM\nDROPOUT = 0.1 # Dropout probability\nLEARNING_RATE = 0.0003 # Learning rate\nNUM_WORKERS = 8\n### ------------------ ###\n\n### Data preprocessing parameters\nFEATURE_SIGMA = 2.0 # Sigma for feature gaussian smoothing\nTARGET_SIGMA = 30.0 # Sigma for target gaussian smoothing\n### ------------------ ###\n\n### Device for training\nDEVICE = \"cuda:0\" # You can choose GPU or CPU\n### ------------------ ###\n\n### Training and testing setting\nDATA_DIR = '/kaggle/input/comp7310-project-1-imu-indoor-tracking/original_data/train_dataset' # Dataset directory for training\nVAL_DATA_DIR = '/kaggle/input/comp7310-project-1-imu-indoor-tracking/original_data/val_dataset' # Dataset directory for validation\nTEST_DIR = '/kaggle/input/comp7310-project-1-imu-indoor-tracking/original_data/test_seen' # Dataset directory for testing (unseen_subjects_test_set)\nOUT_DIR = '/kaggle/working/prediction_model' # Output directory for both traning and testing\nMODEL_PATH = '' # Model path for testing\n### ------------------ ###\n\ndef load_config():\n    kwargs = {}\n    kwargs['batch_size'] = BATCH_SIZE\n    kwargs['test_batch_size'] = TEST_BATCH_SIZE\n    kwargs['epochs'] = EPOCHS\n    kwargs['save_interval'] = SAVE_INTERVAL\n    kwargs['step_size'] = STEP_SIZE\n    kwargs['test_step_size'] = TEST_STEP_SIZE\n    kwargs['window_size'] = WINDOW_SIZE\n    kwargs['sampling_rate'] = SAMPLING_RATE\n    kwargs['input_channel'] = INPUT_CHANNEL\n    kwargs['output_channel'] = OUTPUT_CHANNEL\n    kwargs['layer_size'] = LAYER_SIZE\n    kwargs['layers'] = LAYERS\n    kwargs['dropout'] = DROPOUT\n    kwargs['learning_rate'] = LEARNING_RATE\n    kwargs['num_workers'] = NUM_WORKERS\n\n    kwargs['feature_sigma'] = FEATURE_SIGMA\n    kwargs['target_sigma'] = TARGET_SIGMA\n\n    kwargs['device'] = DEVICE\n\n    kwargs['data_dir'] = DATA_DIR\n    kwargs['val_data_dir'] = VAL_DATA_DIR\n    kwargs['test_dir'] = TEST_DIR\n    kwargs['out_dir'] = OUT_DIR\n    kwargs['model_path'] = MODEL_PATH\n\n    return kwargs\n","metadata":{"execution":{"iopub.status.busy":"2023-10-27T12:39:28.999210Z","iopub.execute_input":"2023-10-27T12:39:28.999694Z","iopub.status.idle":"2023-10-27T12:39:29.011188Z","shell.execute_reply.started":"2023-10-27T12:39:28.999662Z","shell.execute_reply":"2023-10-27T12:39:29.009918Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"### 2. Model Design","metadata":{}},{"cell_type":"code","source":"import torch\nfrom scipy import signal\nimport numpy as np\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport torchvision.models as models\nfrom torch.nn.utils import weight_norm\n\n### BiLSTM model\nclass BilinearLSTMSeqNetwork(torch.nn.Module):\n    def __init__(self, input_size, out_size, batch_size, device,\n                 lstm_size=100, lstm_layers=3, dropout=0):\n        \"\"\"\n        LSTM network with Bilinear layer\n        Input: torch array [batch x frames x input_size]\n        Output: torch array [batch x frames x out_size]\n        :param input_size: num. channels in input\n        :param out_size: num. channels in output\n        :param batch_size:\n        :param device: torch device\n        :param lstm_size: number of LSTM units per layer\n        :param lstm_layers: number of LSTM layers\n        :param dropout: dropout probability of LSTM (@ref https://pytorch.org/docs/stable/nn.html#lstm)\n        \"\"\"\n        super(BilinearLSTMSeqNetwork, self).__init__()\n        self.input_size = input_size\n        self.lstm_size = lstm_size\n        self.output_size = out_size\n        self.num_layers = lstm_layers\n        self.batch_size = batch_size\n        self.device = device\n\n        self.bilinear = torch.nn.Bilinear(self.input_size, self.input_size, self.input_size * 4)\n        self.lstm = torch.nn.LSTM(self.input_size * 5, self.lstm_size, self.num_layers, batch_first=True, dropout=dropout)\n        self.linear1 = torch.nn.Linear(self.lstm_size + self.input_size * 5, self.output_size * 5)\n        self.linear2 = torch.nn.Linear(self.output_size * 5, self.output_size)\n        self.hidden = self.init_weights()\n\n    def forward(self, input):\n        input_mix = self.bilinear(input, input)\n        input_mix = torch.cat([input, input_mix], dim=2)\n        output, self.hidden = self.lstm(input_mix, self.init_weights())\n        output = torch.cat([input_mix, output], dim=2)\n        output = self.linear1(output)\n        output = self.linear2(output)\n        return output\n\n    def init_weights(self):\n        h0 = torch.zeros(self.num_layers, self.batch_size, self.lstm_size)\n        c0 = torch.zeros(self.num_layers, self.batch_size, self.lstm_size)\n        h0 = h0.to(self.device)\n        c0 = c0.to(self.device)\n        return Variable(h0), Variable(c0)\n### --------------------- End of the model --------------------- ###","metadata":{"execution":{"iopub.status.busy":"2023-10-27T12:39:36.126983Z","iopub.execute_input":"2023-10-27T12:39:36.127386Z","iopub.status.idle":"2023-10-27T12:39:36.141060Z","shell.execute_reply.started":"2023-10-27T12:39:36.127352Z","shell.execute_reply":"2023-10-27T12:39:36.140081Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"### 3. Data Loader","metadata":{}},{"cell_type":"code","source":"!pip install pyquaternion==0.9.9\n!pip install numpy-quaternion==2022.4.3","metadata":{"execution":{"iopub.status.busy":"2023-10-27T12:39:40.861010Z","iopub.execute_input":"2023-10-27T12:39:40.861734Z","iopub.status.idle":"2023-10-27T12:40:04.886174Z","shell.execute_reply.started":"2023-10-27T12:39:40.861697Z","shell.execute_reply":"2023-10-27T12:40:04.885078Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pyquaternion==0.9.9 in /opt/conda/lib/python3.10/site-packages (0.9.9)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pyquaternion==0.9.9) (1.23.5)\nRequirement already satisfied: numpy-quaternion==2022.4.3 in /opt/conda/lib/python3.10/site-packages (2022.4.3)\nRequirement already satisfied: numpy>=1.13 in /opt/conda/lib/python3.10/site-packages (from numpy-quaternion==2022.4.3) (1.23.5)\n","output_type":"stream"}]},{"cell_type":"code","source":"import json\nimport random\nimport os\nfrom os import path as osp\n\nimport h5py\nimport torch\nimport numpy as np\nimport quaternion\nimport math\nfrom scipy.ndimage import gaussian_filter1d\nfrom torch.utils.data import Dataset\n\ndef convert_data(data_path):\n    \"\"\"\n    Data Processing\n    :param data_path\n    This function is used to convert the raw data\n    stored in hdf5 format to numpy array\n    \"\"\"\n    # read hdf5 file\n    file = h5py.File(os.path.join(data_path, 'data.hdf5'), 'r')\n    synced = file['synced'] # synced data (gyro, acce, magn ...)\n    pose = file['pose'] # pose data (ground truth)\n    # timestamp (1D)\n    timestamps = np.array(synced['time'])\n    timestamps = timestamps.reshape((len(timestamps), 1)) / 10**9 # - timestamps[0] # start from 0\n    timestamps = timestamps - timestamps[0]\n    # gyroscope (3D), accelerometer (3D), magnetometer (3D), rotation vector (4D)\n    gyro = np.array(synced['gyro'])\n    acce = np.array(synced['acce'])\n    # game rotation vector can convert acce and gyro\n    # from body frame to navigation frame\n    rotation_vector = synced['game_rv']\n\n    # position (3D), orientation (4D)\n    pose = file['pose']\n    tango_pos = np.array(pose['tango_pos'])\n    tango_ori = np.array(pose['tango_ori'])\n\n    # Compute the IMU orientation in the Tango coordinate frame.\n    init_tango_ori = quaternion.quaternion(*tango_ori[0])\n    ori = rotation_vector\n    ori_q = quaternion.from_float_array(ori)\n    init_rotor = init_tango_ori * ori_q[0].conj()\n    ori_q = init_rotor * ori_q\n\n    gyro_q = quaternion.from_float_array(np.concatenate([np.zeros([gyro.shape[0], 1]), gyro], axis=1))\n    acce_q = quaternion.from_float_array(np.concatenate([np.zeros([acce.shape[0], 1]), acce], axis=1))\n    glob_gyro = quaternion.as_float_array(ori_q * gyro_q * ori_q.conj())[:, 1:]\n    glob_acce = quaternion.as_float_array(ori_q * acce_q * ori_q.conj())[:, 1:]\n\n    rawdata = np.concatenate((timestamps, glob_gyro, glob_acce), axis = 1)\n    groundtruth = np.concatenate((timestamps, tango_pos, tango_ori), axis = 1)\n\n    return rawdata, groundtruth\n\ndef convert_data_test(data_path):\n    \"\"\"\n    Data Processing\n    :param data_path\n    This function is used to convert the raw data\n    stored in hdf5 format to numpy array\n    \"\"\"\n    # read hdf5 file\n    file = h5py.File(os.path.join(data_path, 'data.hdf5'), 'r')\n    synced = file['synced'] # synced data (gyro, acce, magn ...)\n    pose = file['pose'] # pose data (ground truth)\n    # timestamp (1D)\n    timestamps = np.array(synced['time'])\n    timestamps = timestamps.reshape((len(timestamps), 1)) / 10**9 # - timestamps[0] # start from 0\n    timestamps = timestamps - timestamps[0]\n    # gyroscope (3D), accelerometer (3D), magnetometer (3D), rotation vector (4D)\n    gyro = np.array(synced['gyro'])\n    acce = np.array(synced['acce'])\n    # game rotation vector can convert acce and gyro\n    # from body frame to navigation frame\n    rotation_vector = synced['game_rv']\n\n    # position (3D), orientation (4D)\n    pose = file['pose']\n    tango_ori = np.array(pose['tango_ori'])\n\n    # Compute the IMU orientation in the Tango coordinate frame.\n    init_tango_ori = quaternion.quaternion(*tango_ori[0])\n    ori = rotation_vector\n    ori_q = quaternion.from_float_array(ori)\n    init_rotor = init_tango_ori * ori_q[0].conj()\n    ori_q = init_rotor * ori_q\n\n    gyro_q = quaternion.from_float_array(np.concatenate([np.zeros([gyro.shape[0], 1]), gyro], axis=1))\n    acce_q = quaternion.from_float_array(np.concatenate([np.zeros([acce.shape[0], 1]), acce], axis=1))\n    glob_gyro = quaternion.as_float_array(ori_q * gyro_q * ori_q.conj())[:, 1:]\n    glob_acce = quaternion.as_float_array(ori_q * acce_q * ori_q.conj())[:, 1:]\n\n    rawdata = np.concatenate((timestamps, glob_gyro, glob_acce), axis = 1)\n\n    return rawdata\n\nclass GlobSequence():\n    \"\"\"\n    Property: global coordinate frame\n    \"\"\"\n    # add 3-axis magnetometer\n    # feature_dim = 9\n    feature_dim = 6\n    target_dim = 2\n    aux_dim = 8\n\n    def __init__(self, data_path = None, **kwargs):\n        super().__init__()\n        self.ts, self.features, self.targets, self.gt_pos = None, None, None, None\n        # self.info = {}\n        self.w = kwargs.get('interval', 1)\n        if data_path is not None:\n            self.load(data_path)\n\n    def load(self, data_path):\n        # print(\"the data_path is:\", data_path)\n        data, ground_truth = convert_data(data_path)\n        # already in global coordinate frame and start from start frame\n        # timestamp (1D) gyroscope (3D), accelerometer (3D)\n        gyro = data[:, 1:4]\n        acce = data[:, 4:7]\n        ts = data[:, 0]\n        # tango position\n        tango_pos = ground_truth[:, 1:4]\n        # tango orientation\n        tango_ori = ground_truth[:, 4:8]\n\n        dt = (ts[self.w:] - ts[:-self.w])[:, None]\n        # calculate the global velocity\n        glob_v = (tango_pos[self.w:] - tango_pos[:-self.w]) / dt\n\n        self.ts = ts\n        self.features = np.concatenate([gyro, acce], axis = 1)\n        # We only use the global velocity in the floor plane\n        self.targets = glob_v[:, :2]\n        self.orientations = tango_ori # quaternion.as_float_array(tango_ori)\n        self.gt_pos = tango_pos\n\n    def get_feature(self):\n        return self.features\n\n    def get_target(self):\n        return self.targets\n\n    def get_aux(self):\n        return np.concatenate([self.ts[:, None], self.orientations, self.gt_pos], axis = 1)\n\nclass GlobSequenceTest():\n    \"\"\"\n    Property: global coordinate frame\n    \"\"\"\n    # add 3-axis magnetometer\n    # feature_dim = 9\n    feature_dim = 6\n    aux_dim = 8\n\n    def __init__(self, data_path = None, **kwargs):\n        super().__init__()\n        self.ts, self.features, self.targets, self.gt_pos = None, None, None, None\n        # self.info = {}\n        self.w = kwargs.get('interval', 1)\n        if data_path is not None:\n            self.load(data_path)\n\n    def load(self, data_path):\n        # print(\"the data_path is:\", data_path)\n        data = convert_data_test(data_path)\n        # already in global coordinate frame and start from start frame\n        # timestamp (1D) gyroscope (3D), accelerometer (3D)\n        gyro = data[:, 1:4]\n        acce = data[:, 4:7]\n        ts = data[:, 0]\n\n        dt = (ts[self.w:] - ts[:-self.w])[:, None]\n\n        self.ts = ts\n        self.features = np.concatenate([gyro, acce], axis = 1)\n\n    def get_feature(self):\n        return self.features\n\n    def get_aux(self):\n        return 0\n\ndef load_sequences(seq_type, root_dir, data_list, **kwargs):\n    features_all, targets_all, aux_all = [], [], []\n\n    for i in range(len(data_list)):\n        seq = seq_type(osp.join(root_dir, data_list[i]), **kwargs)\n        feat, targ, aux = seq.get_feature(), seq.get_target(), seq.get_aux()\n        # add feat, targ, aux to list\n        features_all.append(feat)\n        targets_all.append(targ)\n        aux_all.append(aux)\n    return features_all, targets_all, aux_all\n\ndef load_sequences_test(seq_type, root_dir, data_list, **kwargs):\n    features_all, aux_all = [], []\n\n    for i in range(len(data_list)):\n        seq = seq_type(osp.join(root_dir, data_list[i]), **kwargs)\n        feat, aux = seq.get_feature(), seq.get_aux()\n        # add feat, targ, aux to list\n        features_all.append(feat)\n        aux_all.append(aux)\n    return features_all, aux_all\n\nclass SequenceToSequenceDataset(Dataset):\n    def __init__(self, seq_type, root_dir, data_list, step_size = 100, window_size = 400,\n                 random_shift = 0, transform = None, **kwargs):\n        super(SequenceToSequenceDataset, self).__init__()\n        self.seq_type = seq_type\n        self.feature_dim = seq_type.feature_dim\n        self.target_dim = seq_type.target_dim\n        self.aux_dim = seq_type.aux_dim\n        self.window_size = window_size\n        self.step_size = step_size\n        self.random_shift = random_shift\n        self.transform = transform\n        self.projection_width = kwargs.get('projection_width', 0)\n\n        self.data_path = [osp.join(root_dir, data) for data in data_list]\n        self.index_map = []\n\n        self.features, self.targets, aux = load_sequences(\n            seq_type, root_dir, data_list, **kwargs)\n\n        # Optionally smooth the sequence\n        feat_sigma = kwargs.get('feature_sigma,', -1)\n        targ_sigma = kwargs.get('target_sigma,', -1)\n        if feat_sigma > 0:\n            self.features = [gaussian_filter1d(feat, sigma=feat_sigma, axis=0) for feat in self.features]\n        if targ_sigma > 0:\n            self.targets = [gaussian_filter1d(targ, sigma=targ_sigma, axis=0) for targ in self.targets]\n\n        max_norm = 3.0 #\n        self.ts, self.orientations, self.gt_pos, self.local_v = [], [], [], []\n        for i in range(len(data_list)):\n            self.features[i] = self.features[i][:-1]\n            self.targets[i] = self.targets[i]\n            self.ts.append(aux[i][:-1, :1])\n            self.orientations.append(aux[i][:-1, 1:5])\n            self.gt_pos.append(aux[i][:-1, 5:8])\n\n            velocity = np.linalg.norm(self.targets[i], axis=1)  # Remove outlier ground truth data\n            bad_data = velocity > max_norm\n            for j in range(window_size + random_shift, self.targets[i].shape[0], step_size):\n                if not bad_data[j - window_size - random_shift:j + random_shift].any():\n                    self.index_map.append([i, j])\n\n        # if shuffle is necessary here? As the training data should be in a logical sequence\n        if kwargs.get('shuffle', True):\n            random.shuffle(self.index_map)\n\n    def __getitem__(self, item):\n        # output format: input, target, seq_id, frame_id\n        seq_id, frame_id = self.index_map[item][0], self.index_map[item][1]\n\n        feat = np.copy(self.features[seq_id][frame_id - self.window_size:frame_id])\n        targ = np.copy(self.targets[seq_id][frame_id - self.window_size:frame_id])\n        # random rotate the sequence in the horizontal plane\n        if self.transform is not None:\n            feat, targ = self.transform(feat, targ)\n\n            return feat.astype(np.float32), targ.astype(np.float32), seq_id, frame_id\n\n    def __len__(self):\n        return len(self.index_map)\n\n    def get_lstm_test_seq(self):\n        return np.array(self.features).astype(np.float32), np.array(self.targets).astype(np.float32)\n\nclass SequenceToSequenceDatasetTest(Dataset):\n    def __init__(self, seq_type, root_dir, data_list, step_size = 100, window_size = 400,\n                 random_shift = 0, transform = None, **kwargs):\n        super(SequenceToSequenceDatasetTest, self).__init__()\n        self.seq_type = seq_type\n        self.feature_dim = seq_type.feature_dim\n        self.aux_dim = seq_type.aux_dim\n        self.window_size = window_size\n        self.step_size = step_size\n        self.random_shift = random_shift\n        self.transform = transform\n        self.projection_width = kwargs.get('projection_width', 0)\n\n        self.data_path = [osp.join(root_dir, data) for data in data_list]\n        self.index_map = []\n\n        self.features, aux = load_sequences_test(\n            seq_type, root_dir, data_list, **kwargs)\n\n        # Optionally smooth the sequence\n        feat_sigma = kwargs.get('feature_sigma,', -1)\n        if feat_sigma > 0:\n            self.features = [gaussian_filter1d(feat, sigma=feat_sigma, axis=0) for feat in self.features]\n\n        max_norm = 3.0 #\n        for i in range(len(data_list)):\n            self.features[i] = self.features[i][:-1]\n\n        # if shuffle is necessary here? As the training data should be in a logical sequence\n        if kwargs.get('shuffle', True):\n            random.shuffle(self.index_map)\n\n    def __getitem__(self, item):\n        # output format: input, target, seq_id, frame_id\n        seq_id, frame_id = self.index_map[item][0], self.index_map[item][1]\n        feat = np.copy(self.features[seq_id][frame_id - self.window_size:frame_id])\n\n        return feat.astype(np.float32), seq_id, frame_id\n\n    def __len__(self):\n        return len(self.index_map)\n\n    def get_lstm_test_seq(self):\n        return np.array(self.features).astype(np.float32)\n\ndef change_cf(ori, vectors):\n    \"\"\"\n    Euler-Rodrigous formula v'=v+2s(rxv)+2rx(rxv)\n    :param ori: quaternion [n]x4\n    :param vectors: vector nx3\n    :return: rotated vector nx3\n    \"\"\"\n    assert ori.shape[-1] == 4\n    assert vectors.shape[-1] == 3\n\n    if len(ori.shape) == 1:\n        ori = ori.reshape(1, -1)\n\n    q_s = ori[:, :1]\n    q_r = ori[:, 1:]\n\n    tmp = np.cross(q_r, vectors)\n    vectors = np.add(np.add(vectors, np.multiply(2, np.multiply(q_s, tmp))), np.multiply(2, np.cross(q_r, tmp)))\n    return vectors\n\nclass ComposeTransform:\n    def __init__(self, transforms):\n        self.transforms = transforms\n\n    def __call__(self, feat, targ, **kwargs):\n        for t in self.transforms:\n            feat, targ = t(feat, targ)\n        return feat, targ\n\nclass RandomHoriRotateSeq:\n    def __init__(self, input_format, output_format=None):\n        \"\"\"\n        Rotate global input, global output by a random angle\n        @:param input format - input feature vector(x,3) boundaries as array (E.g [0,3,6])\n        @:param output format - output feature vector(x,2/3) boundaries as array (E.g [0,2,5])\n                                if 2, 0 is appended as z.\n        \"\"\"\n        self.i_f = input_format\n        self.o_f = output_format\n\n    def __call__(self, feature, target):\n        a = np.random.random() * 2 * np.math.pi\n        # print(\"Rotating by {} degrees\", a/np.math.pi * 180)\n        t = np.array([np.cos(a), 0, 0, np.sin(a)])\n\n        for i in range(len(self.i_f) - 1):\n            feature[:, self.i_f[i]: self.i_f[i + 1]] = \\\n                change_cf(t, feature[:, self.i_f[i]: self.i_f[i + 1]])\n\n        for i in range(len(self.o_f) - 1):\n            if self.o_f[i + 1] - self.o_f[i] == 3:\n                # vector = target[:, self.o_f[i]: self.o_f[i + 1]]\n                # target[:, self.o_f[i]: self.o_f[i + 1]] = change_cf(t, vector)\n                vector = target[self.o_f[i]: self.o_f[i + 1]]\n                target[:, self.o_f[i]: self.o_f[i + 1]] = change_cf(t, vector)\n            elif self.o_f[i + 1] - self.o_f[i] == 2:\n                vector = np.concatenate([target[:, self.o_f[i]: self.o_f[i + 1]], np.zeros([target.shape[0], 1])], axis=1)\n                target[:, self.o_f[i]: self.o_f[i + 1]] = change_cf(t, vector)[:, :2]\n\n        return feature.astype(np.float32), target.astype(np.float32)\n\nclass RandomHoriRotateSeqTensor:\n    def __init__(self):\n        \"\"\"\n        Rotate global input, global output by a random angle\n        @:param input format - input feature vector(x,3) boundaries as array (E.g [0,3,6])\n        @:param output format - output feature vector(x,2/3) boundaries as array (E.g [0,2,5])\n                                if 2, 0 is appended as z.\n        \"\"\"\n\n    def __call__(self, feature, target):\n        # Tensor random rotation matrix\n        a = torch.rand(1) * 2 * np.math.pi\n        rotation_matrix_feat = torch.tensor([[torch.cos(a), torch.sin(a), 0, 0, 0, 0],\n                                            [-torch.sin(a), torch.cos(a), 0, 0, 0, 0],\n                                            [0, 0, 1, 0, 0, 0],\n                                            [0, 0, 0, torch.cos(a), torch.sin(a), 0],\n                                            [0, 0, 0, -torch.sin(a), torch.cos(a), 0],\n                                            [0, 0, 0, 0, 0, 1]], dtype=torch.float32)\n\n        rotation_matrix_targ = torch.tensor([[torch.cos(a), torch.sin(a)],\n                                            [-torch.sin(a), torch.cos(a)]], dtype=torch.float32)\n\n        # Matrix multiplication\n        feature = torch.matmul(feature, rotation_matrix_feat)\n        target = torch.matmul(target, rotation_matrix_targ)\n\n        return feature, target\n\ndef get_dataset(root_dir, data_list, mode, **kwargs):\n    # load config\n    global_step_size = 0\n    # input data includes: accelemeters, gyroscopes\n    input_format = [0, 3, 6]\n    # output data is the moving distance and its direction\n    output_format = [0, 2]\n\n    random_shift, shuffle, transforms = 0, False, []\n\n    if mode == 'train':\n        random_shift = global_step_size // 2\n        shuffle = True\n        transforms.append(RandomHoriRotateSeq(input_format, output_format))\n        global_step_size = kwargs.get('step_size')\n        transforms = ComposeTransform(transforms)\n        seq_type = GlobSequence\n        global_window_size = kwargs.get('window_size')\n        dataset = SequenceToSequenceDataset(seq_type, root_dir, data_list, global_step_size,\n                                            global_window_size, random_shift = random_shift,\n                                            transform = transforms, shuffle = shuffle)\n    elif mode == 'val':\n        shuffle = True\n        global_step_size = kwargs.get('step_size')\n        transforms = ComposeTransform(transforms)\n        seq_type = GlobSequence\n        global_window_size = kwargs.get('window_size')\n        dataset = SequenceToSequenceDataset(seq_type, root_dir, data_list, global_step_size,\n                                            global_window_size, random_shift = random_shift,\n                                            transform = transforms, shuffle = shuffle)\n    elif mode == 'val_test':\n        shuffle = False\n        global_step_size = kwargs.get('test_step_size')\n        transforms = ComposeTransform(transforms)\n        seq_type = GlobSequence\n        global_window_size = kwargs.get('window_size')\n        dataset = SequenceToSequenceDataset(seq_type, root_dir, data_list, global_step_size,\n                                            global_window_size, random_shift = random_shift,\n                                            transform = transforms, shuffle = shuffle)\n    elif mode == 'test':\n        shuffle = False\n        global_step_size = kwargs.get('test_step_size')\n        transforms = ComposeTransform(transforms)\n        seq_type = GlobSequenceTest\n        global_window_size = kwargs.get('window_size')\n        dataset = SequenceToSequenceDatasetTest(seq_type, root_dir, data_list, global_step_size,\n                                                global_window_size, random_shift = random_shift,\n                                                transform = transforms, shuffle = shuffle)\n\n    return dataset\n\ndef read_dir(dir_path):\n    # read dirs from dir_path\n    for _, dirs, _ in os.walk(dir_path):\n        return dirs\n\ndef get_train_dataset(root_dir, **kwargs):\n    trainlist = read_dir(root_dir)\n    return get_dataset(root_dir, trainlist, mode = 'train', **kwargs)\n\ndef get_valid_dataset(root_dir, **kwargs):\n    validlist = read_dir(root_dir)\n    return get_dataset(root_dir, validlist, mode = 'val', **kwargs)\n\ndef get_valid_test_dataset(root_dir, dir, **kwargs):\n    return get_dataset(root_dir, dir, mode = 'val_test', **kwargs)\n\ndef get_test_dataset(root_dir, dir, **kwargs):\n    return get_dataset(root_dir, dir, mode = 'test', **kwargs)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T12:41:03.445680Z","iopub.execute_input":"2023-10-27T12:41:03.446094Z","iopub.status.idle":"2023-10-27T12:41:03.529248Z","shell.execute_reply.started":"2023-10-27T12:41:03.446062Z","shell.execute_reply":"2023-10-27T12:41:03.528411Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"### 4. Criterion","metadata":{}},{"cell_type":"code","source":"import json\nimport os\nimport sys\nimport time\nimport random\nimport argparse\nfrom os import path as osp\nfrom pathlib import Path\n\nimport numpy as np\nimport torch\n\nclass GlobalPosLoss(torch.nn.Module):\n    def __init__(self):\n        \"\"\"\n        Calculate position loss in global coordinate frame\n        Target :- Global Velocity\n        Prediction :- Global Velocity\n        \"\"\"\n        super(GlobalPosLoss, self).__init__()\n        self.mse_loss = torch.nn.MSELoss(reduction = 'none')\n\n    def forward(self, pred, targ):\n        # dts = 1 / 200\n        dts = 1\n        pred = pred * dts\n        targ = targ * dts\n        gt_pos = torch.cumsum(targ[:, 1:, ], 1)\n        pred_pos = torch.cumsum(pred[:, 1:, ], 1)\n        loss = self.mse_loss(pred_pos, gt_pos)\n        # calculate the sum of absolute trajectory error\n        return torch.mean(loss)\n\nclass MSEAverage():\n    def __init__(self):\n        self.count = 0\n        self.targets = []\n        self.predictions = []\n        self.average = []\n\n    def add(self, pred, targ):\n        self.targets.append(targ)\n        self.predictions.append(pred)\n        self.average.append(np.average((pred - targ) ** 2, axis=(0, 1)))\n        # print(\"The shape of average is: \", np.array(self.average).shape)\n        # print(\"THe shape of np.average(np.array(self.average), axis=0) is: \", np.average(np.array(self.average), axis=0).shape)\n        self.count += 1\n\n    def get_channel_avg(self):\n        average = np.average(np.array(self.average), axis=0)\n        return average\n\n    def get_total_avg(self):\n        average = np.average(np.array(self.average), axis=0)\n        return np.average(average)\n\n    def get_elements(self, axis):\n        return np.concatenate(self.predictions, axis=axis), np.concatenate(self.targets, axis=axis)\n\ndef reconstruct_traj(vector, **kwargs):\n    global_sampling_rate = kwargs.get('sampling_rate', None)\n    # reconstruct the vector to one sequence\n    # velocity_sequence = vector.reshape(len(vector) * global_window_size, global_output_channel)\n\n    velocity_sequence = vector * 1 / global_sampling_rate\n    glob_pos = np.cumsum(velocity_sequence, axis = 0)\n\n    return glob_pos\n\ndef compute_absolute_trajectory_error(pred, gt):\n    \"\"\"\n    The Absolute Trajectory Error (ATE) defined in:\n    A Benchmark for the evaluation of RGB-D SLAM Systems\n    http://ais.informatik.uni-freiburg.de/publications/papers/sturm12iros.pdf\n\n    Args:\n        est: estimated trajectory\n        gt: ground truth trajectory. It must have the same shape as est.\n\n    Return:\n        Absolution trajectory error, which is the Root Mean Squared Error between\n        two trajectories.\n    \"\"\"\n    return np.sqrt(np.mean((pred - gt) ** 2))\n\n\ndef compute_relative_trajectory_error(est, gt, delta, max_delta = -1):\n    \"\"\"\n    The Relative Trajectory Error (RTE) defined in:\n    A Benchmark for the evaluation of RGB-D SLAM Systems\n    http://ais.informatik.uni-freiburg.de/publications/papers/sturm12iros.pdf\n\n    Args:\n        est: the estimated trajectory\n        gt: the ground truth trajectory.\n        delta: fixed window size. If set to -1, the average of all RTE up to max_delta will be computed.\n        max_delta: maximum delta. If -1 is provided, it will be set to the length of trajectories.\n\n    Returns:\n        Relative trajectory error. This is the mean value under different delta.\n    \"\"\"\n    if max_delta == -1:\n        max_delta = est.shape[0]\n    # print(\"delta: \", delta)\n    deltas = np.array([min(delta, max_delta - 1)])\n    # deltas = np.array([delta]) if delta > 0 else np.arange(1, min(est.shape[0], max_delta))\n    rtes = np.zeros(deltas.shape[0])\n    for i in range(deltas.shape[0]):\n        # For each delta, the RTE is computed as the RMSE of endpoint drifts from fixed windows\n        # slided through the trajectory.\n        err = est[deltas[i]:] + gt[:-deltas[i]] - est[:-deltas[i]] - gt[deltas[i]:]\n        rtes[i] = np.sqrt(np.mean(err ** 2))\n\n    # The average of RTE of all window sized is returned.\n    rtes = rtes[~np.isnan(rtes)]\n    return np.mean(rtes)\n\ndef compute_position_drift_error(pos_pred, pos_gt):\n    \"\"\"\n    Params:\n        pos_pred: predicted position [seq_len, 2]\n        pos_gt: ground truth position [seq_len, 2]\n    \"\"\"\n    position_drift = np.linalg.norm((pos_gt[-1] - pos_pred[-1]))\n    delta_position = pos_gt[1:] - pos_gt[:-1]\n    delta_length = np.linalg.norm(delta_position, axis=1)\n    moving_len = np.sum(delta_length)\n\n    return position_drift / moving_len\n\ndef compute_distance_error(pos_pred, pos_gt):\n    \"\"\"\n    Params:\n        pos_pred: predicted position [seq_len, 2]\n        pos_gt: ground truth position [seq_len, 2]\n    \"\"\"\n    distance_error = np.linalg.norm((pos_gt - pos_pred), axis=1)\n\n    return distance_error\n\ndef compute_heading_error(preds, targets):\n    \"\"\"\n    Params:\n        pos_pred: predicted position [seq_len, 2]\n        pos_gt: ground truth position [seq_len, 2]\n    \"\"\"\n    # Find the index of preds with zero norm\n    zero_norm_index = np.where(np.linalg.norm(preds, axis=1) == 0)[0]\n    # Remove the zero norm index\n    preds = np.delete(preds, zero_norm_index, axis=0)\n    targets = np.delete(targets, zero_norm_index, axis=0)\n    # Find the index of targets with zero norm\n    zero_norm_index = np.where(np.linalg.norm(targets, axis=1) == 0)[0]\n    # Remove the zero norm index\n    preds = np.delete(preds, zero_norm_index, axis=0)\n    targets = np.delete(targets, zero_norm_index, axis=0)\n\n    pred_v = np.linalg.norm(preds, axis=1)\n    targ_v = np.linalg.norm(targets, axis=1)\n\n    pred_o = preds / pred_v[:, np.newaxis]\n    targ_o = targets / targ_v[:, np.newaxis]\n\n    # calculate the heading angle of the predicted and target vectors\n    pred_heading = np.arctan2(pred_o[:, 1], pred_o[:, 0])\n    targ_heading = np.arctan2(targ_o[:, 1], targ_o[:, 0])\n\n    # calculate the heading error\n    heading_error = np.mean(np.abs(pred_heading - targ_heading))\n    # convert to degrees\n    heading_error = heading_error * 180 / np.pi\n\n    return heading_error","metadata":{"execution":{"iopub.status.busy":"2023-10-27T12:41:19.746468Z","iopub.execute_input":"2023-10-27T12:41:19.747369Z","iopub.status.idle":"2023-10-27T12:41:19.774063Z","shell.execute_reply.started":"2023-10-27T12:41:19.747332Z","shell.execute_reply":"2023-10-27T12:41:19.773253Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"### 5. Utils","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os.path as osp\n\ndef format_string(*argv, sep=' '):\n    result = ''\n    for val in argv:\n        if isinstance(val, (tuple, list, np.ndarray)):\n            for v in val:\n                result += format_string(v, sep=sep) + sep\n        else:\n            result += str(val) + sep\n    return result[:-1]\n\ndef draw_trajectory(pos_pred, pos_gt, dir_name, ate, rte, **kwargs):\n    \"\"\"\n    :param data:\n    :pos_pred: (N, 2)\n    :pos_gt: (N, 2)\n    :dir_name: test directory\n    :ate: average trajectory error\n    :rte: relative trajectory error\n    \"\"\"\n    global_out_dir = kwargs.get('out_dir', None)\n    if global_out_dir is None:\n        raise ValueError('out_dir is needed')\n\n    plt.figure(figsize=(8, 5), dpi = 400)\n    plt.plot(pos_pred[:, 0], pos_pred[:, 1], label = 'Predicted')\n    plt.plot(pos_gt[:, 0], pos_gt[:, 1], label = 'Ground truth')\n    plt.title(dir_name)\n    print(\"make title success\")\n    # Show words in latex format\n    plt.xlabel('$m$')\n    plt.ylabel('$m$')\n    plt.axis('equal')\n    plt.legend()\n    plt.title('ATE:{:.3f}, RTE:{:.3f}'.format(ate, rte), y = 0, loc = 'right')\n    plt.show()\n    plt.savefig(osp.join(global_out_dir, '{}.png'.format(dir_name)))\n\npos_pred= (N, 2)\npos_gt= (N, 2)\ndir_name= '/kaggle/working/test_results'\ndraw_trajectory(pos_pred, pos_gt, dir_name, ate, rte, out_dir='output_directory')\n","metadata":{"execution":{"iopub.status.busy":"2023-10-27T14:06:53.310503Z","iopub.execute_input":"2023-10-27T14:06:53.311402Z","iopub.status.idle":"2023-10-27T14:06:53.364232Z","shell.execute_reply.started":"2023-10-27T14:06:53.311368Z","shell.execute_reply":"2023-10-27T14:06:53.362565Z"},"trusted":true},"execution_count":47,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[47], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     41\u001b[0m     plt\u001b[38;5;241m.\u001b[39msavefig(osp\u001b[38;5;241m.\u001b[39mjoin(global_out_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(dir_name)))\n\u001b[0;32m---> 43\u001b[0m pos_pred\u001b[38;5;241m=\u001b[39m (\u001b[43mN\u001b[49m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     44\u001b[0m pos_gt\u001b[38;5;241m=\u001b[39m (N, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     45\u001b[0m dir_name\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/working/test_results\u001b[39m\u001b[38;5;124m'\u001b[39m\n","\u001b[0;31mNameError\u001b[0m: name 'N' is not defined"],"ename":"NameError","evalue":"name 'N' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"### 6. Main Function","metadata":{}},{"cell_type":"code","source":"import os\nimport time\nimport argparse\nfrom os import path as osp\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport numpy as np\nimport torch\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.utils.data import DataLoader\n\ndef get_model(mode, **kwargs):\n    global_input_channel = kwargs.get('input_channel')\n    global_output_channel = kwargs.get('output_channel')\n    global_dropout = kwargs.get('dropout')\n    global_batch_size = kwargs.get('batch_size')\n    global_test_batch_size = kwargs.get('test_batch_size')\n    global_device = kwargs.get('device')\n    global_layers = kwargs.get('layers')\n    global_layer_size = kwargs.get('layer_size')\n\n    if mode == 'train':\n        print(\"LSTM model\")\n        network = BilinearLSTMSeqNetwork(global_input_channel, global_output_channel, global_batch_size, global_device,\n                        lstm_size = global_layer_size, lstm_layers = global_layers, dropout = global_dropout).to(global_device)\n    elif mode == 'test':\n        print(\"LSTM model\")\n        network = BilinearLSTMSeqNetwork(global_input_channel, global_output_channel, global_test_batch_size, global_device,\n                        lstm_size = global_layer_size, lstm_layers = global_layers, dropout = global_dropout).to(global_device)\n    try:\n        pytorch_total_params = sum(p.numel() for p in network.parameters() if p.requires_grad)\n    except:\n        pytorch_total_params = 0\n    print('Network constructed. trainable parameters: {}'.format(pytorch_total_params))\n    return network\n\ndef train(**kwargs):\n    # load config\n    global_data_dir = kwargs.get('data_dir')\n    global_val_data_dir = kwargs.get('val_data_dir')\n    global_batch_size = kwargs.get('batch_size')\n    global_epochs = kwargs.get('epochs')\n    global_num_workers = kwargs.get('num_workers')\n    global_device = kwargs.get('device')\n    global_out_dir = kwargs.get('out_dir', None)\n    global_learning_rate = kwargs.get('learning_rate')\n    global_save_interval = kwargs.get('save_interval')\n    global_sampling_rate = kwargs.get('sampling_rate')\n    # Loading data\n    start_t = time.time()\n    train_dataset = get_train_dataset(global_data_dir, **kwargs)\n    val_dataset = get_valid_dataset(global_val_data_dir, **kwargs)\n    train_loader = DataLoader(train_dataset, batch_size = global_batch_size, num_workers = global_num_workers, shuffle = True,\n                              drop_last = True)\n    val_loader = DataLoader(val_dataset, batch_size = global_batch_size, shuffle = True, drop_last = True)\n    end_t = time.time()\n    print('Training and validation set loaded. Time usage: {:.3f}s'.format(end_t - start_t))\n    # read val for sequence test\n    test_dirs = read_dir(global_val_data_dir)\n\n\n\n    global device\n    device = torch.device(global_device if torch.cuda.is_available() else 'cpu')\n    print(\"Device: {}\".format(device))\n\n    if global_out_dir:\n        if not osp.isdir(global_out_dir):\n            os.makedirs(global_out_dir)\n        if not osp.isdir(osp.join(global_out_dir, 'checkpoints')):\n            os.makedirs(osp.join(global_out_dir, 'checkpoints'))\n\n    print('\\nNumber of train samples: {}'.format(len(train_dataset)))\n    train_mini_batches = len(train_loader)\n    if val_dataset:\n        print('Number of val samples: {}'.format(len(val_dataset)))\n        val_mini_batches = len(val_loader)\n\n    network = get_model('train', **kwargs).to(device)\n    testnetwork = get_model('test', **kwargs).to(device)\n    criterion = GlobalPosLoss()\n\n    optimizer = torch.optim.Adam(network.parameters(), global_learning_rate)\n    scheduler = ReduceLROnPlateau(optimizer, 'min', patience = 10, factor = 0.75, verbose = True, eps = 1e-12)\n    quiet_mode = kwargs.get('quiet', False)\n    use_scheduler = kwargs.get('use_scheduler', True)\n\n    start_epoch = 0\n    step = 0\n    best_val_loss = np.inf\n    train_errs = np.zeros(global_epochs)\n\n    print(\"Starting from epoch {}\".format(start_epoch))\n    try:\n        for epoch in range(start_epoch, global_epochs):\n            log_line = ''\n            network.train()\n            train_vel = MSEAverage()\n            train_loss = 0\n            start_t = time.time()\n\n            for bid, batch in enumerate(tqdm(train_loader)):\n                feat, targ, _, _ = batch\n                feat, targ = feat.to(device), targ.to(device)\n                optimizer.zero_grad()\n                predicted = network(feat)\n                train_vel.add(predicted.cpu().detach().numpy(), targ.cpu().detach().numpy())\n                loss = criterion(predicted, targ)\n                train_loss += loss.cpu().detach().numpy()\n                loss.backward()\n                optimizer.step()\n                step += 1\n\n            train_errs[epoch] = train_loss / train_mini_batches\n            end_t = time.time()\n            if not quiet_mode:\n                print('-' * 25)\n                print('Epoch {}, time usage: {:.3f}s, loss: {}, vec_loss {}/{:.6f}'.format(\n                    epoch, end_t - start_t, train_errs[epoch], train_vel.get_channel_avg(), train_vel.get_total_avg()))\n\n            saved_model = False\n            if val_loader:\n                network.eval()\n                val_vel = MSEAverage()\n                val_loss = 0\n                for bid, batch in enumerate(val_loader):\n                    feat, targ, _, _ = batch\n                    feat, targ = feat.to(device), targ.to(device)\n                    optimizer.zero_grad()\n                    pred = network(feat)\n                    val_vel.add(pred.cpu().detach().numpy(), targ.cpu().detach().numpy())\n                    val_loss += criterion(pred, targ).cpu().detach().numpy()\n                val_loss = val_loss / val_mini_batches\n\n                if not quiet_mode:\n                    print('Validation loss: {} vec_loss: {}/{:.6f}'.format(val_loss, val_vel.get_channel_avg(),\n                                                                                val_vel.get_total_avg()))\n\n                if val_loss < best_val_loss:\n                    best_val_loss = val_loss\n                    saved_model = True\n                    if global_out_dir:\n                        model_path = osp.join(global_out_dir, 'checkpoints', 'checkpoint_%d.pt' % epoch)\n                        torch.save({'model_state_dict': network.state_dict(),\n                                    'epoch': epoch,\n                                    'loss': train_errs[epoch],\n                                    'optimizer_state_dict': optimizer.state_dict()}, model_path)\n                        print('Best Validation Model saved to ' + model_path)\n                if use_scheduler:\n                    scheduler.step(val_loss)\n\n            print(\"Reconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\")\n            testnetwork.load_state_dict(network.state_dict())\n            network.eval().to(device)\n            ate_all, rte_all, pde_all = [], [], []\n            aye_all = []\n            # Every minute\n            pred_per_min = global_sampling_rate * 60 # 2 + 0.5*(x - 1) = 60\n            # Test for every sequence\n            for i in range(len(test_dirs)):\n            # for i in range(1):\n                seq_dir = [test_dirs[i]]\n                seq_dataset = get_valid_test_dataset(global_val_data_dir, seq_dir, **kwargs)\n                feat, targ = seq_dataset.get_lstm_test_seq()\n\n                feat = torch.from_numpy(feat).to(device)\n                pred = testnetwork(feat).cpu().detach().numpy()\n\n                pred = np.squeeze(pred, axis = 0)\n                targ = np.squeeze(targ, axis = 0)\n                # Reconstruct the trajectory\n                pos_pred = reconstruct_traj(pred, **kwargs)\n                pos_gt = reconstruct_traj(targ, **kwargs)\n\n                # Compute the ATE and RTE\n                ate = compute_absolute_trajectory_error(pos_pred, pos_gt)\n                rte = compute_relative_trajectory_error(pos_pred, pos_gt, delta = pred_per_min)\n                pde = compute_position_drift_error(pos_pred, pos_gt)\n                heading_error = compute_heading_error(pred, targ)\n                ate_all.append(ate)\n                if rte >= 0:\n                    rte_all.append(rte)\n                pde_all.append(pde)\n                aye_all.append(heading_error)\n\n            ate_all = np.array(ate_all)\n            rte_all = np.array(rte_all)\n            pde_all = np.array(pde_all)\n            aye_all = np.array(aye_all)\n\n            measure = format_string('ATE', 'RTE', 'PDE', 'AYE',  sep = '\\t')\n            values = format_string(np.mean(ate_all), np.mean(rte_all), np.mean(pde_all), np.mean(aye_all), sep = '\\t')\n            print(measure + '\\n' + values)\n\n            if global_out_dir and not saved_model and (epoch + 1) % global_save_interval == 0:  # save even with validation\n                model_path = osp.join(global_out_dir, 'checkpoints', 'icheckpoint_%d.pt' % epoch)\n                torch.save({'ate': np .mean(ate_all),\n                            'rte': np.mean(rte_all),\n                            'pde': np.mean(pde_all),\n                            'aye': np.mean(aye_all),}, model_path)\n                torch.save({'model_state_dict': network.state_dict(),\n                            'epoch': epoch,\n                            'loss': train_errs[epoch],\n                            'optimizer_state_dict': optimizer.state_dict()}, model_path)\n                print('Model saved to ' + model_path)\n\n            if np.isnan(train_loss):\n                print(\"Invalid value. Stopping training.\")\n                break\n    except KeyboardInterrupt:\n        print('-' * 60)\n        print('Early terminate')\n\n    print('Training completed')\n    if global_out_dir:\n        model_path = osp.join(global_out_dir, 'checkpoints', 'checkpoint_latest.pt')\n        torch.save({'model_state_dict': network.state_dict(),\n                    'epoch': epoch,\n                    'optimizer_state_dict': optimizer.state_dict()}, model_path)\n\n# Test and Save the Trajectory for Both Seen and Unseen Data\nseen_unseen_dataset = {'id1': 'tracermini_hw101_test20230311112635T',\n                'id2': 'tracermini_hw101_test20230311111507T',\n                'id3': 'tracermini_hw101_test20230311112235T',\n                'id4': 'tracermini_hw101_test20230313011357T',\n                'id5': 'tracermini_hw101_test20230311111842T',\n                'id6': 'tracermini_hw101_test20230313010954T',\n                'id7': 'tracermini_hw101_test20230313010546T',\n                'id8': 'tracermini_hw101_test20230313011731T',\n                'id9': 'tracermini_hw101_test20230313013335T',\n                'id10': 'tracermini_hw101_test20230311111027T',\n                'id11': 'tracermini_hw101_test20230313012956T',\n                'id12': 'tracermini_hw101_test20230313010204T',\n                'id13': 'tracermini_unseen_hw520230314091844T',\n                'id14': 'tracermini_unseen_cym20230314101001T',\n                'id15': 'tracermini_unseen_hw520230314082319T',\n                'id16': 'tracermini_unseen_cym20230314101636T',\n                'id17': 'tracermini_unseen_hw520230314083031T',\n                'id18': 'tracermini_unseen_hw520230314091110T',\n                'id19': 'tracermini_unseen_cym20230314100816T',\n                'id20': 'tracermini_unseen_cym20230314101230T',\n                'id21': 'tracermini_unseen_cym20230314100559T',\n                'id22': 'tracermini_unseen_hw520230314081212T',\n                'id23': 'tracermini_unseen_hw520230314082000T',\n                'id24': 'tracermini_unseen_hw520230314091603T',\n                'id25': 'tracermini_unseen_cym20230314100325T',\n                'id26': 'tracermini_unseen_cym20230314101434T',\n                'id27': 'tracermini_unseen_cym20230314100103T',\n                'id28': 'tracermini_unseen_hw520230314091338T',\n                'id29': 'tracermini_unseen_cym20230314101010T',\n                'id30': 'tracermini_unseen_cym20230314101850T',\n                'id31': 'tracermini_unseen_hw520230314081542T',\n                'id32': 'tracermini_unseen_hw520230314090739T'}\nseen_unseen_pred = {'id1': [],\n            'id2': [],\n            'id3': [],\n            'id4': [],\n            'id5': [],\n            'id6': [],\n            'id7': [],\n            'id8': [],\n            'id9': [],\n            'id10': [],\n            'id11': [],\n            'id12': [],\n            'id13': [],\n            'id14': [],\n            'id15': [],\n            'id16': [],\n            'id17': [],\n            'id18': [],\n            'id19': [],\n            'id20': [],\n            'id21': [],\n            'id22': [],\n            'id23': [],\n            'id24': [],\n            'id25': [],\n            'id26': [],\n            'id27': [],\n            'id28': [],\n            'id29': [],\n            'id30': [],\n            'id31': [],\n            'id32': []}\ndef test_lstm(**kwargs):\n    # load config\n    global_dataset = kwargs.get('dataset')\n    global_model_type = kwargs.get('model_type')\n    global_num_workers = kwargs.get('num_workers')\n    global_sampling_rate = kwargs.get('sampling_rate')\n    global_device = kwargs.get('device')\n    global_out_dir = kwargs.get('out_dir', None)\n    global_test_dir = kwargs.get('test_dir', None)\n    global_out_dir = kwargs.get('out_dir', None)\n    global_model_path = kwargs.get('model_path', None)\n\n    global device\n    device = torch.device(global_device if torch.cuda.is_available() else 'cpu')\n\n    if global_test_dir is None:\n        raise ValueError('Test_path is needed.')\n\n    # read dirs\n    test_dirs = read_dir(global_test_dir)\n\n    # Make sure the test output dir exists\n    if global_out_dir and not osp.exists(global_out_dir):\n        os.makedirs(global_out_dir)\n    # Load the model config\n    if global_model_path is None:\n        raise ValueError('Model path is needed.')\n\n    checkpoint = torch.load(global_model_path, map_location=global_device)\n\n    network = get_model('test', **kwargs)\n    network.load_state_dict(checkpoint.get('model_state_dict'))\n    # network.load_state_dict(checkpoint.get('model_state_dict'))\n    print(\"The model is loaded.\")\n    network.eval().to(device)\n    print('Model {} loaded to device {}.'.format(global_model_path, device))\n\n    # Test for every sequence\n    for i in range(len(test_dirs)):\n    # for i in range(1):\n        seq_dir = [test_dirs[i]]\n        seq_dataset = get_test_dataset(global_test_dir, seq_dir, **kwargs)\n        feat = seq_dataset.get_lstm_test_seq()\n\n        feat = torch.from_numpy(feat).to(device)\n        pred = network(feat).cpu().detach().numpy()\n\n        pred = np.squeeze(pred, axis = 0)\n\n        # Reconstruct the trajectory\n        print(\"Reconstruct the {}\".format(seq_dir[0]))\n        pos_pred = reconstruct_traj(pred, **kwargs)\n\n        # Find the index of the sequence\n        for key, value in seen_unseen_dataset.items():\n            if value == seq_dir[0]:\n                index = key\n                seen_unseen_pred[index] = pos_pred\n\n        # # Make directory\n        # if global_out_dir and not osp.exists(osp.join(global_out_dir, seq_dir[0])):\n        #     os.makedirs(osp.join(global_out_dir, seq_dir[0]))\n        # # Save the trajectory\n        # np.save(osp.join(global_out_dir, seq_dir[0], 'pred.npy'), pos_pred)\n\ndef test(**kwargs):\n    # Model type\n    print(\"Testing LSTM model\")\n    test_lstm(**kwargs)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T12:41:31.081531Z","iopub.execute_input":"2023-10-27T12:41:31.081931Z","iopub.status.idle":"2023-10-27T12:41:31.138128Z","shell.execute_reply.started":"2023-10-27T12:41:31.081889Z","shell.execute_reply":"2023-10-27T12:41:31.137295Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"### 7. Training","metadata":{}},{"cell_type":"code","source":"# Load config settings\nkwargs = load_config()\n\nimport warnings\n# Suspend warnings\nwarnings.filterwarnings('ignore')\ntrain(**kwargs)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T12:41:48.220819Z","iopub.execute_input":"2023-10-27T12:41:48.221942Z","iopub.status.idle":"2023-10-27T13:28:00.330769Z","shell.execute_reply.started":"2023-10-27T12:41:48.221890Z","shell.execute_reply":"2023-10-27T13:28:00.329664Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Training and validation set loaded. Time usage: 12.639s\nDevice: cuda:0\n\nNumber of train samples: 18634\nNumber of val samples: 3270\nLSTM model\nNetwork constructed. trainable parameters: 216620\nLSTM model\nNetwork constructed. trainable parameters: 216620\nStarting from epoch 0\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 24.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 0, time usage: 10.402s, loss: 6231.685725722202, vec_loss [0.27687997 0.34201962]/0.309450\nValidation loss: 4251.38990342882 vec_loss: [0.31316587 0.35118878]/0.332177\nBest Validation Model saved to /kaggle/working/prediction_model/checkpoints/checkpoint_0.pt\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n17.489653\t9.011737216602672\t0.32183152\t119.31425731404524\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 1, time usage: 10.253s, loss: 3582.7976869095205, vec_loss [0.27719176 0.48369846]/0.380445\nValidation loss: 3534.950244140625 vec_loss: [0.25240335 0.4703616 ]/0.361382\nBest Validation Model saved to /kaggle/working/prediction_model/checkpoints/checkpoint_1.pt\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n22.017792\t10.387772560119629\t0.39470088\t111.90974423655649\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 2, time usage: 10.288s, loss: 3320.765686508297, vec_loss [0.23451698 0.52801895]/0.381268\nValidation loss: 2861.336691623264 vec_loss: [0.19581926 0.45754877]/0.326684\nBest Validation Model saved to /kaggle/working/prediction_model/checkpoints/checkpoint_2.pt\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n30.567223\t13.011122876947576\t0.56549996\t117.34427428398895\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 3, time usage: 10.142s, loss: 3113.277181935865, vec_loss [0.1975892  0.45087337]/0.324231\nValidation loss: 2859.6264377170137 vec_loss: [0.19801208 0.3491679 ]/0.273590\nBest Validation Model saved to /kaggle/working/prediction_model/checkpoints/checkpoint_3.pt\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n18.921253\t9.464521278034557\t0.3405883\t110.75101568331591\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 24.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 4, time usage: 10.399s, loss: 2933.0286023043845, vec_loss [0.1858126  0.37985796]/0.282835\nValidation loss: 2687.579931640625 vec_loss: [0.16014013 0.3421206 ]/0.251130\nBest Validation Model saved to /kaggle/working/prediction_model/checkpoints/checkpoint_4.pt\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n13.293316\t7.9177279038862745\t0.23081931\t104.24184912985146\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 5, time usage: 10.158s, loss: 2813.747224556383, vec_loss [0.17310004 0.3417965 ]/0.257448\nValidation loss: 2549.1943739149306 vec_loss: [0.15817368 0.29140264]/0.224788\nBest Validation Model saved to /kaggle/working/prediction_model/checkpoints/checkpoint_5.pt\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n26.192657\t10.699111765081232\t0.49024618\t110.35610283847382\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 6, time usage: 10.213s, loss: 2766.5345236608223, vec_loss [0.17444341 0.30622843]/0.240336\nValidation loss: 3139.0931206597224 vec_loss: [0.17816557 0.2819229 ]/0.230044\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n12.99671\t5.722079428759488\t0.22365032\t90.17810527542284\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 7, time usage: 10.170s, loss: 2576.9627598015836, vec_loss [0.17031042 0.28298017]/0.226645\nValidation loss: 2205.071511501736 vec_loss: [0.14933573 0.24721536]/0.198276\nBest Validation Model saved to /kaggle/working/prediction_model/checkpoints/checkpoint_7.pt\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n14.3639345\t6.188002933155406\t0.25182846\t97.46343155189487\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 8, time usage: 10.180s, loss: 2545.132871406023, vec_loss [0.16281165 0.26769388]/0.215253\nValidation loss: 2830.7053955078127 vec_loss: [0.14895198 0.26608032]/0.207516\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n27.857359\t9.94462758844549\t0.5013234\t99.93217983219701\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 9, time usage: 10.299s, loss: 2504.1118821728137, vec_loss [0.16067211 0.27177548]/0.216224\nValidation loss: 2261.465131293403 vec_loss: [0.15206492 0.24580202]/0.198933\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n8.808211\t4.827901406721636\t0.14279361\t84.76305492750329\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 10, time usage: 10.169s, loss: 2342.183153729106, vec_loss [0.15412046 0.27070004]/0.212410\nValidation loss: 2055.9482123480902 vec_loss: [0.13877141 0.242378  ]/0.190575\nBest Validation Model saved to /kaggle/working/prediction_model/checkpoints/checkpoint_10.pt\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n7.130753\t3.5152304606004194\t0.11507973\t87.20398446824228\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 11, time usage: 10.166s, loss: 2347.016940567845, vec_loss [0.1594503  0.26998118]/0.214716\nValidation loss: 1954.4348090277779 vec_loss: [0.15052205 0.24209578]/0.196309\nBest Validation Model saved to /kaggle/working/prediction_model/checkpoints/checkpoint_11.pt\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n15.965393\t6.067760944366455\t0.29275963\t87.80159186967255\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 12, time usage: 10.246s, loss: 2333.817286055217, vec_loss [0.16526112 0.26277223]/0.214017\nValidation loss: 2093.711764865451 vec_loss: [0.14294259 0.2539258 ]/0.198434\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n17.446156\t6.488318161530928\t0.32412165\t87.8327319439512\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 13, time usage: 10.150s, loss: 2267.5608572553297, vec_loss [0.15428352 0.2885424 ]/0.221413\nValidation loss: 1862.6039984809029 vec_loss: [0.13464794 0.24830036]/0.191474\nBest Validation Model saved to /kaggle/working/prediction_model/checkpoints/checkpoint_13.pt\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n6.9646077\t3.63158934766596\t0.11741492\t84.43519839622722\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 14, time usage: 10.208s, loss: 2214.1620835888293, vec_loss [0.15802737 0.28112257]/0.219575\nValidation loss: 2108.45090874566 vec_loss: [0.14920686 0.2661271 ]/0.207667\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n12.734095\t5.0034480528398\t0.23645209\t89.79966808871139\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 15, time usage: 10.137s, loss: 2255.0547416746153, vec_loss [0.15922491 0.2770152 ]/0.218120\nValidation loss: 1902.0355170355904 vec_loss: [0.16236146 0.25241357]/0.207388\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n10.052685\t4.2975616021589795\t0.18149933\t84.75774662866561\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 16, time usage: 10.171s, loss: 2120.6286453128787, vec_loss [0.16191278 0.273125  ]/0.217519\nValidation loss: 1722.67291531033 vec_loss: [0.1344919  0.24901205]/0.191752\nBest Validation Model saved to /kaggle/working/prediction_model/checkpoints/checkpoint_16.pt\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n7.3602366\t3.58837628364563\t0.12806179\t84.18145624763496\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 17, time usage: 10.146s, loss: 2143.1654996650163, vec_loss [0.15195525 0.271295  ]/0.211625\nValidation loss: 2141.5477105034724 vec_loss: [0.1629073  0.25119045]/0.207049\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n12.975432\t5.2561657645485615\t0.24864879\t78.85006702408003\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 18, time usage: 10.192s, loss: 2125.1647215850594, vec_loss [0.15716992 0.2762029 ]/0.216686\nValidation loss: 2116.2652777777776 vec_loss: [0.1604551 0.2776858]/0.219070\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n11.282751\t4.75612245906483\t0.21195358\t84.02781300503437\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 24.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 19, time usage: 10.351s, loss: 2102.9707177923633, vec_loss [0.15698385 0.27664474]/0.216814\nValidation loss: 1894.3981119791667 vec_loss: [0.15078877 0.23709299]/0.193941\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n7.6665893\t3.8909741314974697\t0.14211892\t85.65736077906861\nModel saved to /kaggle/working/prediction_model/checkpoints/icheckpoint_19.pt\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 20, time usage: 10.147s, loss: 2039.4086613618126, vec_loss [0.15268712 0.2724987 ]/0.212593\nValidation loss: 1879.3773003472222 vec_loss: [0.1365245  0.27383557]/0.205180\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n14.13045\t5.4432831460779365\t0.26949927\t82.80634481778317\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 21, time usage: 10.185s, loss: 2040.564459985541, vec_loss [0.15552582 0.26762322]/0.211575\nValidation loss: 1765.5643174913193 vec_loss: [0.1507226 0.2192913]/0.185007\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n7.6903896\t3.962141838940707\t0.14006573\t80.16787006216394\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 22, time usage: 10.171s, loss: 1950.0990288313044, vec_loss [0.15690252 0.24759007]/0.202246\nValidation loss: 1724.9018798828124 vec_loss: [0.15081392 0.24070464]/0.195759\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n8.954512\t4.100091197273948\t0.16675091\t82.90342726386689\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 23, time usage: 10.182s, loss: 1972.5088780129602, vec_loss [0.1521423  0.26027805]/0.206210\nValidation loss: 1603.8458713107639 vec_loss: [0.1389426  0.21287791]/0.175910\nBest Validation Model saved to /kaggle/working/prediction_model/checkpoints/checkpoint_23.pt\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n7.315404\t3.5889184149828823\t0.14215566\t74.6038477001098\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 24, time usage: 10.177s, loss: 1977.21106430172, vec_loss [0.1460762 0.2583184]/0.202197\nValidation loss: 1726.7187269422743 vec_loss: [0.12555619 0.24113734]/0.183347\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n11.320698\t4.83999549258839\t0.21094304\t80.38897384134415\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 25, time usage: 10.151s, loss: 1918.0672027824462, vec_loss [0.14619517 0.25619122]/0.201193\nValidation loss: 1716.0901638454861 vec_loss: [0.12482962 0.22650515]/0.175667\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n8.150663\t3.91960072517395\t0.13917781\t82.52777803618937\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 24.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 26, time usage: 10.331s, loss: 1980.8824507838997, vec_loss [0.1430872  0.25139043]/0.197239\nValidation loss: 1535.6253662109375 vec_loss: [0.12895124 0.23462638]/0.181789\nBest Validation Model saved to /kaggle/working/prediction_model/checkpoints/checkpoint_26.pt\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n9.748684\t4.366967504674738\t0.15457183\t83.19576681145888\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 27, time usage: 10.152s, loss: 1857.0992043665212, vec_loss [0.14491546 0.23550135]/0.190208\nValidation loss: 1591.946149359809 vec_loss: [0.14108743 0.22702283]/0.184055\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n5.6776967\t3.1733072129162876\t0.11237728\t78.10074621895285\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 28, time usage: 10.240s, loss: 1885.7590824097626, vec_loss [0.13991734 0.24214242]/0.191030\nValidation loss: 1565.345145670573 vec_loss: [0.13461453 0.21964084]/0.177128\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n8.807873\t3.9474116455424917\t0.16741472\t81.11560662082739\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 29, time usage: 10.180s, loss: 1827.354367278343, vec_loss [0.13996984 0.23542102]/0.187695\nValidation loss: 1641.2385226779513 vec_loss: [0.12283069 0.21702372]/0.169927\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n6.009633\t3.7812120697715064\t0.11509531\t82.89676099923696\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 30, time usage: 10.226s, loss: 1814.49172453178, vec_loss [0.13637702 0.24206413]/0.189221\nValidation loss: 1367.8524441189236 vec_loss: [0.11693339 0.20876569]/0.162850\nBest Validation Model saved to /kaggle/working/prediction_model/checkpoints/checkpoint_30.pt\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n6.336218\t3.141607956452803\t0.10395086\t78.98297443328673\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 31, time usage: 10.240s, loss: 1855.7240503592084, vec_loss [0.14249353 0.2376228 ]/0.190058\nValidation loss: 1705.452303059896 vec_loss: [0.13065536 0.22965753]/0.180156\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n13.034088\t5.271572589874268\t0.23054376\t86.84139828781555\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 32, time usage: 10.168s, loss: 1819.055328605711, vec_loss [0.14144604 0.23856287]/0.190004\nValidation loss: 1428.4985785590277 vec_loss: [0.11899353 0.2130021 ]/0.165998\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n4.6169662\t2.8891997770829634\t0.077934176\t76.7986600670754\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 33, time usage: 10.262s, loss: 1745.1436956834423, vec_loss [0.13368562 0.2326111 ]/0.183148\nValidation loss: 1365.1490926106771 vec_loss: [0.11237953 0.20370427]/0.158042\nBest Validation Model saved to /kaggle/working/prediction_model/checkpoints/checkpoint_33.pt\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n8.265734\t3.830613136291504\t0.13548703\t81.21239723155564\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 34, time usage: 10.113s, loss: 1734.4506536675979, vec_loss [0.14376865 0.23291843]/0.188344\nValidation loss: 1497.184507921007 vec_loss: [0.13989143 0.21199428]/0.175943\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n6.605554\t3.9643837972120806\t0.13328968\t79.5338273270694\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 24.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 35, time usage: 10.390s, loss: 1715.8710180474807, vec_loss [0.14026648 0.21909021]/0.179678\nValidation loss: 1681.5441338433159 vec_loss: [0.12816541 0.20240252]/0.165284\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n11.996081\t4.9976444027640605\t0.22829963\t74.25836307151222\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 36, time usage: 10.120s, loss: 1741.9710085373517, vec_loss [0.1343612  0.21212067]/0.173241\nValidation loss: 1609.808322482639 vec_loss: [0.12587541 0.19060585]/0.158241\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n6.162169\t3.3636933240023525\t0.11002014\t75.19765875821412\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 37, time usage: 10.197s, loss: 1693.1103210449219, vec_loss [0.1300098  0.21198305]/0.170996\nValidation loss: 1768.1545166015626 vec_loss: [0.11153096 0.19882414]/0.155178\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n6.556551\t3.670787366953763\t0.12165925\t79.8237850014199\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 38, time usage: 10.323s, loss: 1637.011229877324, vec_loss [0.13060762 0.21154934]/0.171078\nValidation loss: 1301.4941379123263 vec_loss: [0.1191001  0.18890196]/0.154001\nBest Validation Model saved to /kaggle/working/prediction_model/checkpoints/checkpoint_38.pt\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n3.9081519\t2.6679722504182295\t0.062985584\t76.13382683920244\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 39, time usage: 10.202s, loss: 1687.1120546326156, vec_loss [0.12697195 0.20195141]/0.164462\nValidation loss: 1299.9919609917536 vec_loss: [0.11804325 0.18188666]/0.149965\nBest Validation Model saved to /kaggle/working/prediction_model/checkpoints/checkpoint_39.pt\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n8.248328\t3.7353681217540395\t0.14346544\t73.49691185041911\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 40, time usage: 10.196s, loss: 1623.992351798124, vec_loss [0.12676474 0.19433002]/0.160547\nValidation loss: 1355.1442843967013 vec_loss: [0.11943263 0.18452671]/0.151980\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n5.5030065\t2.960660121657632\t0.09264286\t74.80608090846586\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 41, time usage: 10.183s, loss: 1647.0694099840268, vec_loss [0.12808055 0.20829676]/0.168189\nValidation loss: 1348.287178548177 vec_loss: [0.12345931 0.19498801]/0.159224\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n8.163444\t3.6475915908813477\t0.15867567\t72.71087505294541\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 42, time usage: 10.172s, loss: 1681.7583911511324, vec_loss [0.12919614 0.20584378]/0.167520\nValidation loss: 1451.2353271484376 vec_loss: [0.11775406 0.17670825]/0.147231\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n10.514499\t4.456276806918058\t0.20275792\t73.6963111511959\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 43, time usage: 10.149s, loss: 1702.9040898759235, vec_loss [0.12993436 0.2067762 ]/0.168355\nValidation loss: 2095.948074001736 vec_loss: [0.12295185 0.22819822]/0.175575\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n16.06448\t6.331226739016446\t0.30550095\t89.72601691703858\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 44, time usage: 10.250s, loss: 1677.4324191780977, vec_loss [0.12918627 0.1948179 ]/0.162002\nValidation loss: 1229.1601996527777 vec_loss: [0.11356787 0.15520413]/0.134386\nBest Validation Model saved to /kaggle/working/prediction_model/checkpoints/checkpoint_44.pt\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n4.1278\t2.6412189548665825\t0.07320287\t72.6014715665253\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 45, time usage: 10.216s, loss: 1571.0560056701188, vec_loss [0.12634988 0.18538827]/0.155869\nValidation loss: 1461.31806640625 vec_loss: [0.11198892 0.1853581 ]/0.148674\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n7.4141784\t3.5912295905026523\t0.14317946\t71.39536944212776\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 46, time usage: 10.138s, loss: 1578.6378561803538, vec_loss [0.12125573 0.19180636]/0.156531\nValidation loss: 1410.9000691731771 vec_loss: [0.11758117 0.16599427]/0.141788\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n9.572592\t4.106801423159513\t0.18183666\t77.91672850418696\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 47, time usage: 10.283s, loss: 1488.0312832381373, vec_loss [0.12382719 0.18059072]/0.152209\nValidation loss: 1232.5315687391494 vec_loss: [0.10373309 0.16273929]/0.133236\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n5.159708\t2.908699935132807\t0.08714703\t73.77447211049979\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 48, time usage: 10.175s, loss: 1565.034707239432, vec_loss [0.1216304  0.18434922]/0.152990\nValidation loss: 1560.884494357639 vec_loss: [0.12087287 0.1812168 ]/0.151045\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n10.634531\t4.823387622833252\t0.20490307\t69.47481214461082\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 49, time usage: 10.211s, loss: 1558.4084480936212, vec_loss [0.11951696 0.19300853]/0.156263\nValidation loss: 1473.2375298394097 vec_loss: [0.11709653 0.17807347]/0.147585\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n5.026535\t3.3600258176976983\t0.07262395\t80.7792496086661\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 50, time usage: 10.276s, loss: 1557.537225531053, vec_loss [0.12508044 0.19526017]/0.160170\nValidation loss: 1271.2038628472221 vec_loss: [0.09932417 0.17469387]/0.137009\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n5.430409\t2.8952105045318604\t0.10210344\t77.51822608447284\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 51, time usage: 10.254s, loss: 1514.4850265148075, vec_loss [0.11796291 0.18466128]/0.151312\nValidation loss: 1366.6053860134548 vec_loss: [0.10521487 0.16321053]/0.134213\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n5.266081\t3.062692869793285\t0.1006746\t73.24467172251796\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 24.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 52, time usage: 10.378s, loss: 1493.1561064017835, vec_loss [0.11876869 0.1797399 ]/0.149254\nValidation loss: 1405.973597547743 vec_loss: [0.12079586 0.17639968]/0.148598\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n7.4962144\t3.6037153113972056\t0.13811666\t76.50024599760611\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 53, time usage: 10.167s, loss: 1461.9862261631692, vec_loss [0.11586195 0.19000676]/0.152934\nValidation loss: 1296.6485039605034 vec_loss: [0.11107709 0.18695948]/0.149018\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n6.5387287\t3.3559610843658447\t0.116074845\t79.32984931584355\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 54, time usage: 10.321s, loss: 1492.7280398819798, vec_loss [0.12472934 0.18971705]/0.157223\nValidation loss: 1196.7599500868055 vec_loss: [0.10961169 0.16104956]/0.135331\nBest Validation Model saved to /kaggle/working/prediction_model/checkpoints/checkpoint_54.pt\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n6.7405243\t3.3063348423350942\t0.12307267\t77.45551811770297\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 55, time usage: 10.128s, loss: 1482.2167952190073, vec_loss [0.12248344 0.18208778]/0.152286\nValidation loss: 1250.3198825412326 vec_loss: [0.11216889 0.18822077]/0.150195\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n4.960091\t3.0350716655904595\t0.09370511\t71.93830800944124\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 56, time usage: 10.141s, loss: 1456.6246489295663, vec_loss [0.11766449 0.17530663]/0.146486\nValidation loss: 1306.2347412109375 vec_loss: [0.10429568 0.16430317]/0.134299\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n13.325733\t5.317630702799017\t0.24779604\t82.18372277990717\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 57, time usage: 10.297s, loss: 1434.378552459007, vec_loss [0.11770118 0.17169589]/0.144699\nValidation loss: 1314.3411607530381 vec_loss: [0.1099925  0.15074717]/0.130370\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n5.880093\t3.2368331172249536\t0.11068871\t68.7564594171805\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 58, time usage: 10.132s, loss: 1385.320237034051, vec_loss [0.11698619 0.16145562]/0.139221\nValidation loss: 1320.7412109375 vec_loss: [0.1034654  0.17056492]/0.137015\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n7.985142\t3.571103269403631\t0.13189194\t73.44074782580039\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 59, time usage: 10.251s, loss: 1476.1588534569555, vec_loss [0.11758213 0.16949041]/0.143536\nValidation loss: 1262.346240234375 vec_loss: [0.10199223 0.14593935]/0.123966\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n4.533579\t2.8005909486250444\t0.08844454\t71.57369636746247\nModel saved to /kaggle/working/prediction_model/checkpoints/icheckpoint_59.pt\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 60, time usage: 10.131s, loss: 1411.1115922558215, vec_loss [0.11441929 0.16445245]/0.139436\nValidation loss: 1447.6473958333333 vec_loss: [0.10447733 0.16425487]/0.134366\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n13.431113\t5.29665114662864\t0.25033072\t74.45439881458593\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 61, time usage: 10.157s, loss: 1403.616214012915, vec_loss [0.1159866  0.16035554]/0.138171\nValidation loss: 1170.5129896375868 vec_loss: [0.09537084 0.13917363]/0.117272\nBest Validation Model saved to /kaggle/working/prediction_model/checkpoints/checkpoint_61.pt\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n5.1398168\t2.7839153679934414\t0.08974592\t71.54454387823228\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 62, time usage: 10.181s, loss: 1387.351466097573, vec_loss [0.11851026 0.1538566 ]/0.136183\nValidation loss: 1255.5691053602432 vec_loss: [0.1010697  0.13606773]/0.118569\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n5.6026177\t2.8475897203792226\t0.106763\t70.82506168588374\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 63, time usage: 10.159s, loss: 1364.8518980750741, vec_loss [0.11691918 0.1534808 ]/0.135200\nValidation loss: 1286.1233737521702 vec_loss: [0.11292891 0.13926102]/0.126095\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n5.68018\t2.9554462974721734\t0.090577915\t73.80403751571163\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 64, time usage: 10.252s, loss: 1371.436234230219, vec_loss [0.11482825 0.1610451 ]/0.137937\nValidation loss: 1094.0762329101562 vec_loss: [0.09915193 0.15198168]/0.125567\nBest Validation Model saved to /kaggle/working/prediction_model/checkpoints/checkpoint_64.pt\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n9.840249\t4.035350409421054\t0.18254629\t73.42620138564713\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 65, time usage: 10.178s, loss: 1327.9748694841253, vec_loss [0.1127537  0.15377565]/0.133265\nValidation loss: 1244.616593424479 vec_loss: [0.10015886 0.14838743]/0.124273\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n5.219821\t2.98860671303489\t0.10110101\t68.20537926437636\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 24.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 66, time usage: 10.354s, loss: 1430.8337746553643, vec_loss [0.11697467 0.15778574]/0.137380\nValidation loss: 1283.1649956597223 vec_loss: [0.0975806  0.13523798]/0.116409\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n11.103024\t4.500553586266258\t0.19116291\t80.5235024890893\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 67, time usage: 10.201s, loss: 1357.0269623985587, vec_loss [0.11845217 0.15088864]/0.134670\nValidation loss: 1326.869377983941 vec_loss: [0.11636387 0.15543734]/0.135901\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n7.5675244\t3.629561597650701\t0.14009356\t69.78634297145486\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 68, time usage: 10.113s, loss: 1356.8933201279751, vec_loss [0.11778054 0.1558449 ]/0.136813\nValidation loss: 1101.7802585177951 vec_loss: [0.09281593 0.13259992]/0.112708\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n7.2124815\t3.2146058190952647\t0.120996974\t69.84913072725277\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 69, time usage: 10.213s, loss: 1313.5630319284837, vec_loss [0.11697339 0.15154962]/0.134262\nValidation loss: 1073.1453640407985 vec_loss: [0.10130733 0.13607837]/0.118693\nBest Validation Model saved to /kaggle/working/prediction_model/checkpoints/checkpoint_69.pt\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n4.9831476\t2.9073788794604214\t0.08922134\t70.73351293488034\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 70, time usage: 10.121s, loss: 1301.9457979424055, vec_loss [0.11639223 0.14871524]/0.132554\nValidation loss: 1206.7618286132813 vec_loss: [0.10556453 0.14955075]/0.127558\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n5.7838726\t3.0123237046328457\t0.102236815\t72.46791404749487\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 71, time usage: 10.163s, loss: 1315.5229773706244, vec_loss [0.11392351 0.15121888]/0.132571\nValidation loss: 1209.3913275824652 vec_loss: [0.09278546 0.1163175 ]/0.104551\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n3.6865194\t2.598185506733981\t0.058469273\t67.68773847589601\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 72, time usage: 10.129s, loss: 1310.9279457506284, vec_loss [0.1130161  0.14161436]/0.127315\nValidation loss: 1365.5482367621528 vec_loss: [0.10512701 0.12752384]/0.116325\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n7.635783\t3.446214654228904\t0.13300273\t75.24190099809972\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 73, time usage: 10.148s, loss: 1327.0122448825098, vec_loss [0.11458032 0.15018883]/0.132385\nValidation loss: 1201.2328667534723 vec_loss: [0.09658708 0.12585606]/0.111222\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n6.986351\t3.298346909609708\t0.11623206\t70.96179338009938\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 74, time usage: 10.172s, loss: 1315.9688604783641, vec_loss [0.11331339 0.15648292]/0.134898\nValidation loss: 1449.7372463650174 vec_loss: [0.10482005 0.16049625]/0.132658\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n10.951741\t4.672132535414263\t0.20486592\t74.54378487932759\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 75, time usage: 10.149s, loss: 1317.8465699188469, vec_loss [0.11372273 0.15498956]/0.134356\nValidation loss: 1272.5079535590278 vec_loss: [0.10584038 0.15542032]/0.130630\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n6.0399914\t3.2886778874830767\t0.10954382\t76.56768542269197\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 76, time usage: 10.227s, loss: 1258.8414585793664, vec_loss [0.10572159 0.15694277]/0.131332\nValidation loss: 1344.1548638237848 vec_loss: [0.11150476 0.14942458]/0.130465\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n8.777426\t4.3867575255307285\t0.17118317\t70.02119995745518\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 77, time usage: 10.139s, loss: 1235.882593672405, vec_loss [0.10217323 0.15409428]/0.128134\nValidation loss: 1363.9106757269965 vec_loss: [0.08993641 0.13955082]/0.114744\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n11.608835\t4.721093871376731\t0.21432947\t73.23619794146315\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 78, time usage: 10.225s, loss: 1275.1305429621261, vec_loss [0.11238693 0.14645144]/0.129419\nValidation loss: 1181.5230007595487 vec_loss: [0.10385448 0.13613537]/0.119995\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n4.4572554\t3.0652880560268057\t0.07053637\t71.76897892694859\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 79, time usage: 10.089s, loss: 1246.9832253862721, vec_loss [0.11231297 0.14526501]/0.128789\nValidation loss: 1804.9087212456598 vec_loss: [0.11647932 0.17725793]/0.146869\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n15.467093\t6.383971842852506\t0.27377063\t78.84944982334957\nModel saved to /kaggle/working/prediction_model/checkpoints/icheckpoint_79.pt\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 80, time usage: 10.120s, loss: 1261.9831514580305, vec_loss [0.10693015 0.15088269]/0.128906\nValidation loss: 1243.4833577473958 vec_loss: [0.10607036 0.13946745]/0.122769\nEpoch 00081: reducing learning rate of group 0 to 2.2500e-04.\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n3.92829\t2.7665779807350854\t0.069457084\t71.49188684528922\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 81, time usage: 10.188s, loss: 1216.8987122764884, vec_loss [0.1125743  0.15192758]/0.132251\nValidation loss: 1060.1796495225694 vec_loss: [0.10606138 0.1432061 ]/0.124634\nBest Validation Model saved to /kaggle/working/prediction_model/checkpoints/checkpoint_81.pt\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n5.1535783\t2.9201869639483364\t0.10110235\t69.77115977139306\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 82, time usage: 10.150s, loss: 1081.7515386537063, vec_loss [0.10865024 0.15398547]/0.131318\nValidation loss: 1033.5821899414063 vec_loss: [0.08199131 0.13555254]/0.108772\nBest Validation Model saved to /kaggle/working/prediction_model/checkpoints/checkpoint_82.pt\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n4.031681\t2.4828605326739224\t0.07827576\t68.31165824971434\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 83, time usage: 10.246s, loss: 1129.2412271425706, vec_loss [0.10393747 0.15101877]/0.127478\nValidation loss: 1189.483768717448 vec_loss: [0.09632653 0.14904799]/0.122687\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n5.259405\t2.8962230032140557\t0.09224885\t67.82130530882078\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 84, time usage: 10.203s, loss: 1158.2475834336392, vec_loss [0.1090683  0.14772527]/0.128397\nValidation loss: 1304.065121799045 vec_loss: [0.10521103 0.15465128]/0.129931\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n11.387424\t4.6861770369789815\t0.20211278\t76.81294820189281\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 85, time usage: 10.244s, loss: 1201.8466582778813, vec_loss [0.1111699  0.14866884]/0.129919\nValidation loss: 1294.2050645616318 vec_loss: [0.11074061 0.15705639]/0.133898\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n7.2808166\t3.6451701792803677\t0.1428551\t72.1426896227544\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 86, time usage: 10.142s, loss: 1245.2224886398908, vec_loss [0.10669862 0.15544835]/0.131073\nValidation loss: 1140.4359822591146 vec_loss: [0.09191119 0.13520561]/0.113558\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n6.2485323\t3.2093971967697144\t0.1098027\t74.18191524783742\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 87, time usage: 10.115s, loss: 1214.4857293653859, vec_loss [0.10934372 0.1504723 ]/0.129908\nValidation loss: 1251.5327324761286 vec_loss: [0.09768704 0.1435923 ]/0.120640\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n11.009862\t4.48697380586104\t0.19999246\t75.14135564610685\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 88, time usage: 10.279s, loss: 1095.2260496154313, vec_loss [0.10496976 0.15212081]/0.128545\nValidation loss: 1678.5029120551214 vec_loss: [0.10813906 0.14341775]/0.125778\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n8.09355\t4.285809560255571\t0.14163834\t72.57928835395366\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 89, time usage: 10.119s, loss: 1141.9787948371827, vec_loss [0.10949236 0.15051414]/0.130003\nValidation loss: 1288.100008138021 vec_loss: [0.09871569 0.14867222]/0.123694\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n6.857311\t3.747442852367054\t0.12204499\t74.81725758165315\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 90, time usage: 10.182s, loss: 1081.0140736897786, vec_loss [0.10433909 0.14468326]/0.124511\nValidation loss: 1195.021233452691 vec_loss: [0.09851799 0.1556899 ]/0.127104\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n5.627212\t2.8923952796242456\t0.08916369\t69.78868541587703\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 91, time usage: 10.158s, loss: 1076.5633853646211, vec_loss [0.10674446 0.14786775]/0.127306\nValidation loss: 1073.61162109375 vec_loss: [0.1008333  0.14299072]/0.121912\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n5.914068\t2.895843755115162\t0.11221876\t66.24677843410875\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 92, time usage: 10.255s, loss: 1099.7647690883903, vec_loss [0.10816431 0.14957282]/0.128869\nValidation loss: 1121.452288140191 vec_loss: [0.10276274 0.13850866]/0.120636\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n4.6124706\t2.8245975971221924\t0.08059305\t68.72522123654831\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 93, time usage: 10.092s, loss: 1012.9287434659263, vec_loss [0.11065323 0.14198115]/0.126317\nValidation loss: 1201.91533203125 vec_loss: [0.09585244 0.14058174]/0.118217\nEpoch 00094: reducing learning rate of group 0 to 1.6875e-04.\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n10.188477\t4.429918440905484\t0.19062094\t71.7064032174781\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 94, time usage: 10.105s, loss: 1045.50470514815, vec_loss [0.10890415 0.14407589]/0.126490\nValidation loss: 998.9842054578993 vec_loss: [0.09509049 0.13246794]/0.113779\nBest Validation Model saved to /kaggle/working/prediction_model/checkpoints/checkpoint_94.pt\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n4.52443\t2.6812127395109697\t0.080419354\t70.93660674707182\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 95, time usage: 10.292s, loss: 1051.1404213129088, vec_loss [0.10962006 0.14445873]/0.127039\nValidation loss: 1045.1400906032986 vec_loss: [0.09927723 0.1406811 ]/0.119979\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n4.6621575\t2.545417991551486\t0.0836023\t66.62913242384606\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 96, time usage: 10.182s, loss: 1053.3003579073174, vec_loss [0.11163716 0.13981634]/0.125727\nValidation loss: 1027.9958570692274 vec_loss: [0.09736503 0.13797352]/0.117669\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n4.0366898\t2.733622746034102\t0.072945\t67.812234817603\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 24.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 97, time usage: 10.363s, loss: 998.0610189511794, vec_loss [0.104691   0.14524299]/0.124967\nValidation loss: 1036.2691596137154 vec_loss: [0.10353487 0.14037733]/0.121956\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n4.3934236\t2.6206627650694414\t0.08172335\t69.66739367474335\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 98, time usage: 10.243s, loss: 993.7602636056353, vec_loss [0.10893331 0.1464104 ]/0.127672\nValidation loss: 1032.6633246527779 vec_loss: [0.09472505 0.13785547]/0.116290\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n6.338257\t3.0667378143830732\t0.10828335\t72.01554751413347\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 99, time usage: 10.113s, loss: 1023.8642995671709, vec_loss [0.10947244 0.14393395]/0.126703\nValidation loss: 998.4792317708333 vec_loss: [0.10445254 0.14434531]/0.124399\nBest Validation Model saved to /kaggle/working/prediction_model/checkpoints/checkpoint_99.pt\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n6.868645\t3.108125686645508\t0.12498\t69.74346770079268\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 100, time usage: 10.198s, loss: 974.2549695155417, vec_loss [0.10846271 0.1460384 ]/0.127251\nValidation loss: 1057.5443488226997 vec_loss: [0.1034916  0.12331767]/0.113405\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n4.7468944\t2.7314558679407295\t0.07672895\t69.967801538524\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 101, time usage: 10.145s, loss: 977.8987062439438, vec_loss [0.1072774  0.14444388]/0.125861\nValidation loss: 1045.6090969509548 vec_loss: [0.0901682  0.13444002]/0.112304\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n7.8959584\t3.536170092496005\t0.14432849\t72.02000886951409\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 102, time usage: 10.318s, loss: 964.2162483865901, vec_loss [0.10464521 0.14709671]/0.125871\nValidation loss: 1144.6827840169271 vec_loss: [0.10816511 0.14034347]/0.124254\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n5.8231626\t3.3425618301738393\t0.11283507\t68.97682056852005\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 103, time usage: 10.154s, loss: 993.3611582674721, vec_loss [0.11092471 0.14252926]/0.126727\nValidation loss: 1003.898368326823 vec_loss: [0.09663843 0.14157979]/0.119109\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n3.8406768\t2.5206289941614326\t0.06965654\t72.20787198078271\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 104, time usage: 10.192s, loss: 986.1335212648377, vec_loss [0.10497593 0.14796893]/0.126472\nValidation loss: 1076.5731472439236 vec_loss: [0.09675874 0.13625297]/0.116506\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n7.7431183\t3.526787216013128\t0.14219661\t74.54730553138158\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 105, time usage: 10.178s, loss: 929.8378144493399, vec_loss [0.10727102 0.14293024]/0.125101\nValidation loss: 942.4593343098958 vec_loss: [0.09546874 0.13283232]/0.114151\nBest Validation Model saved to /kaggle/working/prediction_model/checkpoints/checkpoint_105.pt\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n3.0875535\t2.328872030431574\t0.058212522\t67.28105038492482\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 106, time usage: 10.138s, loss: 920.9034880408944, vec_loss [0.10756557 0.1431319 ]/0.125349\nValidation loss: 1067.9956637912326 vec_loss: [0.09996216 0.13617532]/0.118069\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n9.020362\t4.015014290809631\t0.16084121\t73.19507771895451\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 107, time usage: 10.241s, loss: 962.8726279088693, vec_loss [0.1071659  0.14202799]/0.124597\nValidation loss: 1147.5411499023437 vec_loss: [0.10643517 0.1469957 ]/0.126715\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n9.676517\t4.408969261429527\t0.1602961\t75.74761379258408\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 108, time usage: 10.135s, loss: 946.2661628427431, vec_loss [0.1083988  0.14008662]/0.124243\nValidation loss: 1348.3271308051214 vec_loss: [0.11776033 0.13011578]/0.123938\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n3.6831815\t2.880445046858354\t0.059832834\t73.13900807513158\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 109, time usage: 10.290s, loss: 983.932557571766, vec_loss [0.10723555 0.13895996]/0.123098\nValidation loss: 1026.6098402235243 vec_loss: [0.10059704 0.13408281]/0.117340\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n4.8237834\t2.8021909323605625\t0.08429841\t72.79581839009512\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 110, time usage: 10.145s, loss: 1059.4964535735373, vec_loss [0.1054944  0.14681222]/0.126153\nValidation loss: 1027.2909342447917 vec_loss: [0.10079519 0.12302928]/0.111912\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n4.62534\t2.7426917769692163\t0.08027355\t70.47638860079634\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 111, time usage: 10.206s, loss: 949.4556807880253, vec_loss [0.10781755 0.13814522]/0.122981\nValidation loss: 1152.842842610677 vec_loss: [0.11031705 0.13091753]/0.120617\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n7.040874\t3.623968341133811\t0.13633636\t67.33472418466481\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 112, time usage: 10.212s, loss: 940.653033707493, vec_loss [0.10299122 0.13888752]/0.120939\nValidation loss: 975.8831359863282 vec_loss: [0.09415624 0.14126898]/0.117713\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n3.9667792\t2.423843882300637\t0.07271708\t65.83002264430094\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 113, time usage: 10.101s, loss: 916.0566873476487, vec_loss [0.1036374  0.13885142]/0.121244\nValidation loss: 1206.902859157986 vec_loss: [0.11720528 0.13889855]/0.128052\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n9.191547\t4.169969981366938\t0.17158101\t68.46358711483323\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 114, time usage: 10.220s, loss: 931.6354323985964, vec_loss [0.10751031 0.13761806]/0.122564\nValidation loss: 1010.5498087565104 vec_loss: [0.0960563  0.12605442]/0.111055\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n4.420374\t2.700398152524775\t0.0770494\t68.03999989400285\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 115, time usage: 10.149s, loss: 925.1560664213905, vec_loss [0.10344063 0.13481402]/0.119127\nValidation loss: 989.1267829047309 vec_loss: [0.08911356 0.13308771]/0.111101\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n7.4020963\t3.590104753320867\t0.1377648\t70.34461562391814\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 24.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 116, time usage: 10.328s, loss: 908.1855131637218, vec_loss [0.10403197 0.13924387]/0.121638\nValidation loss: 1179.0957397460938 vec_loss: [0.10074497 0.13199137]/0.116368\nEpoch 00117: reducing learning rate of group 0 to 1.2656e-04.\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n6.4162326\t3.4076384847814385\t0.12252838\t70.69374571075367\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 117, time usage: 10.160s, loss: 890.7400161388308, vec_loss [0.10233022 0.14347214]/0.122901\nValidation loss: 1032.7568820529514 vec_loss: [0.10231198 0.14128953]/0.121801\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n8.730452\t3.9961246143687856\t0.14883772\t70.7535669912098\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 118, time usage: 10.195s, loss: 888.1349523973096, vec_loss [0.10410143 0.13895755]/0.121529\nValidation loss: 1003.5248969184028 vec_loss: [0.09781466 0.13587792]/0.116846\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n5.2003193\t3.113843885335055\t0.09109226\t70.99194618157983\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 119, time usage: 10.187s, loss: 848.2764771927235, vec_loss [0.10142268 0.13886689]/0.120145\nValidation loss: 1243.7030449761285 vec_loss: [0.11617385 0.1461283 ]/0.131151\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n11.3132\t4.877926566384056\t0.20504206\t74.58094731767534\nModel saved to /kaggle/working/prediction_model/checkpoints/icheckpoint_119.pt\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 120, time usage: 10.176s, loss: 883.6029383932897, vec_loss [0.10268991 0.13725406]/0.119972\nValidation loss: 1102.5541137695313 vec_loss: [0.10496408 0.13778193]/0.121373\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n6.369202\t3.25661039352417\t0.11977029\t70.92945926456854\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 121, time usage: 10.220s, loss: 847.1235185963238, vec_loss [0.10342455 0.13867459]/0.121050\nValidation loss: 953.9444173177084 vec_loss: [0.09302819 0.12383813]/0.108433\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n3.807303\t2.4398494850505483\t0.06684912\t68.82084885233881\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 122, time usage: 10.194s, loss: 866.3497802970945, vec_loss [0.10384918 0.13270608]/0.118278\nValidation loss: 1015.5862182617187 vec_loss: [0.09617706 0.13120903]/0.113693\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n9.151315\t4.0259081667119805\t0.1684536\t71.23665323175275\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 123, time usage: 10.162s, loss: 863.8642712970112, vec_loss [0.10052317 0.13300315]/0.116763\nValidation loss: 993.7603000217014 vec_loss: [0.10192209 0.13774055]/0.119831\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n10.365692\t4.448184923692183\t0.18284798\t72.70452359794358\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 124, time usage: 10.178s, loss: 848.6438241411549, vec_loss [0.10316017 0.13450095]/0.118831\nValidation loss: 948.1390238444011 vec_loss: [0.09398837 0.12947841]/0.111733\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n6.723946\t3.211759242144498\t0.115204625\t70.9492860618765\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 125, time usage: 10.136s, loss: 836.9409236464389, vec_loss [0.10105703 0.13099499]/0.116026\nValidation loss: 1082.4875230577256 vec_loss: [0.09841512 0.1337627 ]/0.116089\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n8.344319\t3.91842963478782\t0.15058622\t70.46586390021164\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 126, time usage: 10.200s, loss: 822.7944655307504, vec_loss [0.10182911 0.13526206]/0.118546\nValidation loss: 946.2277947319878 vec_loss: [0.09720011 0.13863246]/0.117916\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n4.991581\t2.876376899805936\t0.09488084\t67.67384462927164\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 127, time usage: 10.189s, loss: 842.6764166780221, vec_loss [0.09829897 0.1346043 ]/0.116452\nValidation loss: 1114.2062913682726 vec_loss: [0.1051081 0.14281  ]/0.123959\nEpoch 00128: reducing learning rate of group 0 to 9.4922e-05.\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n10.631193\t4.820643533359874\t0.18527803\t72.60512571773126\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 128, time usage: 10.273s, loss: 836.2269754335862, vec_loss [0.09868345 0.13398749]/0.116335\nValidation loss: 1069.670060221354 vec_loss: [0.10320441 0.13823852]/0.120721\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n5.9097843\t3.29885779727589\t0.099748515\t71.77306772655629\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 129, time usage: 10.161s, loss: 795.7204088314559, vec_loss [0.09805309 0.132905  ]/0.115479\nValidation loss: 971.1251085069445 vec_loss: [0.09992956 0.1256929 ]/0.112811\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n7.8765264\t3.669079152020541\t0.13604994\t69.87754307234746\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 130, time usage: 10.164s, loss: 795.0434098354606, vec_loss [0.10217358 0.13196519]/0.117069\nValidation loss: 1024.045650906033 vec_loss: [0.09655978 0.12304993]/0.109805\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n7.082405\t3.325688535516912\t0.13956672\t66.45561488307648\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 131, time usage: 10.206s, loss: 806.1626323138097, vec_loss [0.10292105 0.13290697]/0.117914\nValidation loss: 1031.3955234103732 vec_loss: [0.1035616  0.13826647]/0.120914\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n4.428975\t2.579487908970226\t0.08404786\t68.10246445766775\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 132, time usage: 10.115s, loss: 881.7901477665864, vec_loss [0.10571848 0.13805735]/0.121888\nValidation loss: 1029.7871466742622 vec_loss: [0.09896695 0.12232914]/0.110648\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n3.5625718\t2.6482598889957774\t0.06478787\t66.8577959805849\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 133, time usage: 10.150s, loss: 824.3834550251332, vec_loss [0.09934701 0.13413462]/0.116741\nValidation loss: 963.2663058810764 vec_loss: [0.10291195 0.1338376 ]/0.118375\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n9.289112\t4.282109260559082\t0.15812969\t71.38025174978938\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 134, time usage: 10.177s, loss: 798.4092689928158, vec_loss [0.10241355 0.13118239]/0.116798\nValidation loss: 1012.7077473958333 vec_loss: [0.09781406 0.12493339]/0.111374\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n3.6416426\t2.4475537105040117\t0.06158956\t68.84185354681546\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 135, time usage: 10.127s, loss: 812.0246065124985, vec_loss [0.10014487 0.13304038]/0.116593\nValidation loss: 1067.5325995551216 vec_loss: [0.09934398 0.12967588]/0.114510\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n9.594624\t4.006695487282493\t0.17632093\t71.16372730198451\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 136, time usage: 10.236s, loss: 800.4182707320812, vec_loss [0.09918154 0.12992474]/0.114553\nValidation loss: 945.6022779676649 vec_loss: [0.0934989 0.1265404]/0.110020\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n8.770304\t3.9636550816622647\t0.15434644\t71.71285339975974\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 137, time usage: 10.148s, loss: 791.4742749827777, vec_loss [0.10030297 0.12717865]/0.113741\nValidation loss: 972.5850802951389 vec_loss: [0.10267358 0.13196939]/0.117321\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n5.26074\t3.083827257156372\t0.09285534\t69.33443499215728\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 138, time usage: 10.202s, loss: 790.9724350567012, vec_loss [0.09769913 0.1273742 ]/0.112537\nValidation loss: 908.66036851671 vec_loss: [0.08998753 0.12189384]/0.105941\nBest Validation Model saved to /kaggle/working/prediction_model/checkpoints/checkpoint_138.pt\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n6.8769765\t3.1440143476833\t0.12494873\t70.70831822981103\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 139, time usage: 10.097s, loss: 847.5767165782839, vec_loss [0.10062405 0.13249023]/0.116557\nValidation loss: 914.8404656304253 vec_loss: [0.08733544 0.12087022]/0.104103\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n4.202085\t2.4363280859860508\t0.07764935\t66.75617518426087\nModel saved to /kaggle/working/prediction_model/checkpoints/icheckpoint_139.pt\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 140, time usage: 10.165s, loss: 818.7387750906538, vec_loss [0.09977883 0.12955587]/0.114667\nValidation loss: 981.6172030978732 vec_loss: [0.10217346 0.12595333]/0.114063\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n5.828555\t3.177441943775524\t0.10121079\t70.36719312468277\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 141, time usage: 10.088s, loss: 769.0564671006314, vec_loss [0.10429828 0.12726836]/0.115783\nValidation loss: 949.2754753960503 vec_loss: [0.1031535  0.12428628]/0.113720\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n7.368789\t3.522965344515714\t0.13144493\t68.97649582407134\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 142, time usage: 10.128s, loss: 790.6022622751635, vec_loss [0.10267761 0.12811962]/0.115399\nValidation loss: 934.4181864420573 vec_loss: [0.09538932 0.1269878 ]/0.111189\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n6.1389756\t3.1758647832003506\t0.117678575\t69.92918985821964\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 143, time usage: 10.239s, loss: 764.8191078836604, vec_loss [0.10061154 0.12700194]/0.113807\nValidation loss: 992.6402214898003 vec_loss: [0.10248788 0.13063699]/0.116562\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n7.3705463\t3.5188650868155738\t0.1331792\t68.39479779599688\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 144, time usage: 10.177s, loss: 795.113142383191, vec_loss [0.09886958 0.12930176]/0.114086\nValidation loss: 951.2319620768229 vec_loss: [0.09810895 0.13234   ]/0.115224\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n6.309619\t3.1510352221402256\t0.12020686\t66.49143332647346\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 145, time usage: 10.148s, loss: 751.827265776405, vec_loss [0.09691747 0.12957656]/0.113247\nValidation loss: 911.9638821072049 vec_loss: [0.0920293  0.12358377]/0.107807\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n3.8450887\t2.5231389674273403\t0.06562205\t67.85708991173506\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 146, time usage: 10.162s, loss: 753.6441090901693, vec_loss [0.09484363 0.12632698]/0.110585\nValidation loss: 899.5246141221788 vec_loss: [0.09266023 0.12483371]/0.108747\nBest Validation Model saved to /kaggle/working/prediction_model/checkpoints/checkpoint_146.pt\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n4.1195827\t2.5389111908999356\t0.06755109\t66.85417784310366\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 147, time usage: 10.125s, loss: 799.1540478846823, vec_loss [0.09876986 0.13082145]/0.114796\nValidation loss: 927.8447258843316 vec_loss: [0.08890598 0.11321028]/0.101058\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n6.792725\t3.1362285072153266\t0.1317988\t64.1180798146037\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 148, time usage: 10.265s, loss: 813.160144184911, vec_loss [0.1025702 0.1257487]/0.114159\nValidation loss: 910.3170545789931 vec_loss: [0.10174907 0.11627926]/0.109014\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n3.629222\t2.330399578267878\t0.06567859\t68.27602142725665\n","output_type":"stream"},{"name":"stderr","text":"100%|| 258/258 [00:10<00:00, 25.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"-------------------------\nEpoch 149, time usage: 10.158s, loss: 762.8375784703927, vec_loss [0.10284672 0.12330511]/0.113076\nValidation loss: 1031.197664388021 vec_loss: [0.10543503 0.12984084]/0.117638\nReconstruct the validation trajectory and compute the ATE, RTE, PDE, and AYE\nATE\tRTE\tPDE\tAYE\n6.535742\t3.350755648179488\t0.11837521\t70.05320187742183\nTraining completed\n","output_type":"stream"}]},{"cell_type":"code","source":"# Check Saved Checkpoints\n# Define the directory path\ndir_path = '/kaggle/working/prediction_model/checkpoints'\n\n# Loop over all files in the directory\nfor filename in os.listdir(dir_path):\n    # Check if the file is a regular file (not a directory)\n    if os.path.isfile(os.path.join(dir_path, filename)):\n        # Do something with the file\n        print(filename)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T13:28:08.038683Z","iopub.execute_input":"2023-10-27T13:28:08.039091Z","iopub.status.idle":"2023-10-27T13:28:08.048533Z","shell.execute_reply.started":"2023-10-27T13:28:08.039058Z","shell.execute_reply":"2023-10-27T13:28:08.047526Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"checkpoint_3.pt\ncheckpoint_24.pt\ncheckpoint_1.pt\ncheckpoint_5.pt\ncheckpoint_44.pt\ncheckpoint_92.pt\nicheckpoint_39.pt\nicheckpoint_99.pt\ncheckpoint_138.pt\ncheckpoint_4.pt\ncheckpoint_54.pt\ncheckpoint_50.pt\nicheckpoint_19.pt\ncheckpoint_38.pt\ncheckpoint_13.pt\ncheckpoint_146.pt\ncheckpoint_79.pt\ncheckpoint_31.pt\ncheckpoint_83.pt\ncheckpoint_11.pt\ncheckpoint_30.pt\ncheckpoint_16.pt\ncheckpoint_64.pt\ncheckpoint_59.pt\ncheckpoint_40.pt\ncheckpoint_53.pt\ncheckpoint_65.pt\ncheckpoint_61.pt\ncheckpoint_10.pt\ncheckpoint_111.pt\ncheckpoint_39.pt\ncheckpoint_2.pt\ncheckpoint_69.pt\ncheckpoint_82.pt\ncheckpoint_73.pt\ncheckpoint_26.pt\nicheckpoint_119.pt\ncheckpoint_94.pt\ncheckpoint_22.pt\ncheckpoint_106.pt\ncheckpoint_99.pt\ncheckpoint_0.pt\nicheckpoint_79.pt\ncheckpoint_81.pt\ncheckpoint_85.pt\ncheckpoint_76.pt\ncheckpoint_23.pt\ncheckpoint_42.pt\ncheckpoint_latest.pt\ncheckpoint_7.pt\ncheckpoint_33.pt\nicheckpoint_59.pt\ncheckpoint_17.pt\nicheckpoint_139.pt\ncheckpoint_105.pt\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Download the checkpoints.","metadata":{}},{"cell_type":"code","source":"!zip -r checkpoints.zip /kaggle/working/prediction_model","metadata":{"execution":{"iopub.status.busy":"2023-10-27T13:28:24.447037Z","iopub.execute_input":"2023-10-27T13:28:24.447408Z","iopub.status.idle":"2023-10-27T13:28:32.615588Z","shell.execute_reply.started":"2023-10-27T13:28:24.447377Z","shell.execute_reply":"2023-10-27T13:28:32.614449Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"  adding: kaggle/working/prediction_model/ (stored 0%)\n  adding: kaggle/working/prediction_model/checkpoints/ (stored 0%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_3.pt (deflated 8%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_24.pt (deflated 7%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_1.pt (deflated 8%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_5.pt (deflated 8%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_44.pt (deflated 8%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_92.pt (deflated 7%)\n  adding: kaggle/working/prediction_model/checkpoints/icheckpoint_39.pt (deflated 7%)\n  adding: kaggle/working/prediction_model/checkpoints/icheckpoint_99.pt (deflated 7%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_138.pt (deflated 8%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_4.pt (deflated 7%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_54.pt (deflated 8%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_50.pt (deflated 7%)\n  adding: kaggle/working/prediction_model/checkpoints/icheckpoint_19.pt (deflated 8%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_38.pt (deflated 8%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_13.pt (deflated 7%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_146.pt (deflated 8%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_79.pt (deflated 7%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_31.pt (deflated 7%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_83.pt (deflated 7%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_11.pt (deflated 7%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_30.pt (deflated 8%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_16.pt (deflated 8%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_64.pt (deflated 8%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_59.pt (deflated 7%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_40.pt (deflated 7%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_53.pt (deflated 7%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_65.pt (deflated 7%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_61.pt (deflated 8%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_10.pt (deflated 7%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_111.pt (deflated 7%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_39.pt (deflated 8%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_2.pt (deflated 7%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_69.pt (deflated 8%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_82.pt (deflated 8%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_73.pt (deflated 7%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_26.pt (deflated 8%)\n  adding: kaggle/working/prediction_model/checkpoints/icheckpoint_119.pt (deflated 8%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_94.pt (deflated 8%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_22.pt (deflated 7%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_106.pt (deflated 7%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_99.pt (deflated 8%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_0.pt (deflated 8%)\n  adding: kaggle/working/prediction_model/checkpoints/icheckpoint_79.pt (deflated 8%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_81.pt (deflated 8%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_85.pt (deflated 7%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_76.pt (deflated 7%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_23.pt (deflated 8%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_42.pt (deflated 7%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_latest.pt (deflated 8%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_7.pt (deflated 7%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_33.pt (deflated 8%)\n  adding: kaggle/working/prediction_model/checkpoints/icheckpoint_59.pt (deflated 8%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_17.pt (deflated 7%)\n  adding: kaggle/working/prediction_model/checkpoints/icheckpoint_139.pt (deflated 8%)\n  adding: kaggle/working/prediction_model/checkpoints/checkpoint_105.pt (deflated 8%)\n","output_type":"stream"}]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'checkpoints.zip')","metadata":{"execution":{"iopub.status.busy":"2023-10-27T13:28:46.039506Z","iopub.execute_input":"2023-10-27T13:28:46.040470Z","iopub.status.idle":"2023-10-27T13:28:46.048428Z","shell.execute_reply.started":"2023-10-27T13:28:46.040430Z","shell.execute_reply":"2023-10-27T13:28:46.047522Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/checkpoints.zip","text/html":"<a href='checkpoints.zip' target='_blank'>checkpoints.zip</a><br>"},"metadata":{}}]},{"cell_type":"markdown","source":"### 8. Testing","metadata":{}},{"cell_type":"markdown","source":"#### 8.1 Test for Seen Dataset","metadata":{}},{"cell_type":"code","source":"# Please change the output dir & model path\nTEST_DIR = '/kaggle/input/comp7310-project-1-imu-indoor-tracking/original_data/test_seen' # Dataset directory for testing (unseen_subjects_test_set)\nOUT_DIR = '/kaggle/working/test_results/test_seen' # Output directory for both traning and testing\nMODEL_PATH = '/kaggle/working/prediction_model/checkpoints/checkpoint_105.pt' # Model path for testing\n# Load config settings\nkwargs = load_config()\n\nimport warnings\n# Suspend warnings\nwarnings.filterwarnings('ignore')\ntest(**kwargs)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T13:34:16.192004Z","iopub.execute_input":"2023-10-27T13:34:16.193022Z","iopub.status.idle":"2023-10-27T13:34:21.576396Z","shell.execute_reply.started":"2023-10-27T13:34:16.192981Z","shell.execute_reply":"2023-10-27T13:34:21.575366Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Testing LSTM model\nLSTM model\nNetwork constructed. trainable parameters: 216620\nThe model is loaded.\nModel /kaggle/working/prediction_model/checkpoints/checkpoint_105.pt loaded to device cuda:0.\nReconstruct the tracermini_hw101_test20230313011731T\nReconstruct the tracermini_hw101_test20230311111842T\nReconstruct the tracermini_hw101_test20230311111507T\nReconstruct the tracermini_hw101_test20230311112635T\nReconstruct the tracermini_hw101_test20230313012956T\nReconstruct the tracermini_hw101_test20230313010954T\nReconstruct the tracermini_hw101_test20230313010204T\nReconstruct the tracermini_hw101_test20230311111027T\nReconstruct the tracermini_hw101_test20230313010546T\nReconstruct the tracermini_hw101_test20230311112235T\nReconstruct the tracermini_hw101_test20230313011357T\nReconstruct the tracermini_hw101_test20230313013335T\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### 8.2 Test for Unseen Dataset","metadata":{}},{"cell_type":"code","source":"# Please change the output dir & model path\nTEST_DIR = '/kaggle/input/comp7310-project-1-imu-indoor-tracking/original_data/test_unseen' # Dataset directory for testing (unseen_subjects_test_set)\nOUT_DIR = '/kaggle/working/test_results/test_unseen' # Output directory for both traning and testing\nMODEL_PATH = '/kaggle/working/prediction_model/checkpoints/checkpoint_105.pt' # Model path for testing\n# Load config settings\nkwargs = load_config()\nimport warnings\n# Suspend warnings\nwarnings.filterwarnings('ignore')\ntest(**kwargs)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T13:35:31.871314Z","iopub.execute_input":"2023-10-27T13:35:31.871704Z","iopub.status.idle":"2023-10-27T13:35:37.801535Z","shell.execute_reply.started":"2023-10-27T13:35:31.871673Z","shell.execute_reply":"2023-10-27T13:35:37.800323Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Testing LSTM model\nLSTM model\nNetwork constructed. trainable parameters: 216620\nThe model is loaded.\nModel /kaggle/working/prediction_model/checkpoints/checkpoint_105.pt loaded to device cuda:0.\nReconstruct the tracermini_unseen_cym20230314101010T\nReconstruct the tracermini_unseen_hw520230314081212T\nReconstruct the tracermini_unseen_cym20230314101001T\nReconstruct the tracermini_unseen_hw520230314091603T\nReconstruct the tracermini_unseen_hw520230314083031T\nReconstruct the tracermini_unseen_cym20230314101850T\nReconstruct the tracermini_unseen_cym20230314101230T\nReconstruct the tracermini_unseen_cym20230314100103T\nReconstruct the tracermini_unseen_hw520230314090739T\nReconstruct the tracermini_unseen_cym20230314100325T\nReconstruct the tracermini_unseen_hw520230314082000T\nReconstruct the tracermini_unseen_cym20230314100816T\nReconstruct the tracermini_unseen_hw520230314091844T\nReconstruct the tracermini_unseen_hw520230314091338T\nReconstruct the tracermini_unseen_hw520230314081542T\nReconstruct the tracermini_unseen_hw520230314082319T\nReconstruct the tracermini_unseen_cym20230314100559T\nReconstruct the tracermini_unseen_cym20230314101636T\nReconstruct the tracermini_unseen_hw520230314091110T\nReconstruct the tracermini_unseen_cym20230314101434T\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the checkpoint\ncheckpoint_path = '/kaggle/working/prediction_model/checkpoints/checkpoint_105.pt'\ncheckpoint = torch.load(checkpoint_path, map_location='cpu')\n# Load ATERTEPDE, and AYE values from the checkpoint\nate = checkpoint.get('ate',None)\nrte = checkpoint.get('rte',None)\npde = checkpoint.get('pde',None)  \naye = checkpoint.get('aye',None)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T13:36:36.921250Z","iopub.execute_input":"2023-10-27T13:36:36.921644Z","iopub.status.idle":"2023-10-27T13:36:36.932800Z","shell.execute_reply.started":"2023-10-27T13:36:36.921611Z","shell.execute_reply":"2023-10-27T13:36:36.931836Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"#### 8.3 Check the Results","metadata":{}},{"cell_type":"code","source":"for key, value in seen_unseen_pred.items():\n    # print the length of each sequence\n    print(seen_unseen_dataset[key], len(value))","metadata":{"execution":{"iopub.status.busy":"2023-10-27T13:36:42.830624Z","iopub.execute_input":"2023-10-27T13:36:42.831258Z","iopub.status.idle":"2023-10-27T13:36:42.836708Z","shell.execute_reply.started":"2023-10-27T13:36:42.831222Z","shell.execute_reply":"2023-10-27T13:36:42.835785Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"tracermini_hw101_test20230311112635T 42097\ntracermini_hw101_test20230311111507T 37913\ntracermini_hw101_test20230311112235T 43462\ntracermini_hw101_test20230313011357T 38324\ntracermini_hw101_test20230311111842T 42839\ntracermini_hw101_test20230313010954T 39610\ntracermini_hw101_test20230313010546T 38378\ntracermini_hw101_test20230313011731T 37610\ntracermini_hw101_test20230313013335T 38254\ntracermini_hw101_test20230311111027T 44186\ntracermini_hw101_test20230313012956T 38694\ntracermini_hw101_test20230313010204T 39085\ntracermini_unseen_hw520230314091844T 19545\ntracermini_unseen_cym20230314101001T 283\ntracermini_unseen_hw520230314082319T 31657\ntracermini_unseen_cym20230314101636T 22690\ntracermini_unseen_hw520230314083031T 21208\ntracermini_unseen_hw520230314091110T 25327\ntracermini_unseen_cym20230314100816T 18914\ntracermini_unseen_cym20230314101230T 21364\ntracermini_unseen_cym20230314100559T 24483\ntracermini_unseen_hw520230314081212T 37662\ntracermini_unseen_hw520230314082000T 34311\ntracermini_unseen_hw520230314091603T 30173\ntracermini_unseen_cym20230314100325T 26852\ntracermini_unseen_cym20230314101434T 22394\ntracermini_unseen_cym20230314100103T 21781\ntracermini_unseen_hw520230314091338T 26671\ntracermini_unseen_cym20230314101010T 24564\ntracermini_unseen_cym20230314101850T 18695\ntracermini_unseen_hw520230314081542T 41291\ntracermini_unseen_hw520230314090739T 32802\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### 8.4 Save the Results","metadata":{}},{"cell_type":"code","source":"with open(\"submission.csv\", \"w\") as f:\n    # The first row must be \"Id, Category\"\n    f.write(\"Id,Prediction\\n\")\n\n    # For the rest of the rows, each image id corresponds to a predicted class.\n    for key, value in seen_unseen_pred.items():\n        # print the length of each sequence\n        print(seen_unseen_dataset[key], len(value))\n        # print the prediction\n        for i in range(len(value)):\n            f.write(\"{},{}\\n\".format(key+'_'+str(i), value[i]))","metadata":{"execution":{"iopub.status.busy":"2023-10-27T13:36:48.751103Z","iopub.execute_input":"2023-10-27T13:36:48.751823Z","iopub.status.idle":"2023-10-27T13:38:29.046073Z","shell.execute_reply.started":"2023-10-27T13:36:48.751785Z","shell.execute_reply":"2023-10-27T13:38:29.045254Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"tracermini_hw101_test20230311112635T 42097\ntracermini_hw101_test20230311111507T 37913\ntracermini_hw101_test20230311112235T 43462\ntracermini_hw101_test20230313011357T 38324\ntracermini_hw101_test20230311111842T 42839\ntracermini_hw101_test20230313010954T 39610\ntracermini_hw101_test20230313010546T 38378\ntracermini_hw101_test20230313011731T 37610\ntracermini_hw101_test20230313013335T 38254\ntracermini_hw101_test20230311111027T 44186\ntracermini_hw101_test20230313012956T 38694\ntracermini_hw101_test20230313010204T 39085\ntracermini_unseen_hw520230314091844T 19545\ntracermini_unseen_cym20230314101001T 283\ntracermini_unseen_hw520230314082319T 31657\ntracermini_unseen_cym20230314101636T 22690\ntracermini_unseen_hw520230314083031T 21208\ntracermini_unseen_hw520230314091110T 25327\ntracermini_unseen_cym20230314100816T 18914\ntracermini_unseen_cym20230314101230T 21364\ntracermini_unseen_cym20230314100559T 24483\ntracermini_unseen_hw520230314081212T 37662\ntracermini_unseen_hw520230314082000T 34311\ntracermini_unseen_hw520230314091603T 30173\ntracermini_unseen_cym20230314100325T 26852\ntracermini_unseen_cym20230314101434T 22394\ntracermini_unseen_cym20230314100103T 21781\ntracermini_unseen_hw520230314091338T 26671\ntracermini_unseen_cym20230314101010T 24564\ntracermini_unseen_cym20230314101850T 18695\ntracermini_unseen_hw520230314081542T 41291\ntracermini_unseen_hw520230314090739T 32802\n","output_type":"stream"}]},{"cell_type":"code","source":"#zip\nimport os\nimport zipfile\nimport datetime\n\ndef file2zip(packagePath, zipPath):\n    '''\n  :param packagePath: \n  :param zipPath: \n  :return:\n  '''\n    zip = zipfile.ZipFile(zipPath, 'w', zipfile.ZIP_DEFLATED)\n    for path, dirNames, fileNames in os.walk(packagePath):\n        fpath = path.replace(packagePath, '')\n        for name in fileNames:\n            fullName = os.path.join(path, name)\n            name = fpath + '\\\\' + name\n            zip.write(fullName, name)\n    zip.close()\n\n\nif __name__ == \"__main__\":\n    # \n    packagePath = '/kaggle/working/'\n    zipPath = '/kaggle/working/output.zip'\n    if os.path.exists(zipPath):\n        os.remove(zipPath)\n    file2zip(packagePath, zipPath)\n    print(\"\")\n    print(datetime.datetime.utcnow())\n","metadata":{"execution":{"iopub.status.busy":"2023-10-27T14:16:20.793215Z","iopub.execute_input":"2023-10-27T14:16:20.793997Z","iopub.status.idle":"2023-10-27T14:16:36.120633Z","shell.execute_reply.started":"2023-10-27T14:16:20.793959Z","shell.execute_reply":"2023-10-27T14:16:36.119470Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"\n2023-10-27 14:16:36.116966\n","output_type":"stream"}]}]}